{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Machine vs Machine"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    },
    "tags": [
     "remove-cell"
    ]
   },
   "source": [
    "**CS5483 Data Warehousing and Data Mining**\n",
    "___"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a title=\"Freddycastillo9871, CC BY-SA 4.0 &lt;https://creativecommons.org/licenses/by-sa/4.0&gt;, via Wikimedia Commons\" href=\"https://commons.wikimedia.org/wiki/File:Terminator_2.png\"><img width=\"512\" alt=\"Terminator 2\" src=\"https://upload.wikimedia.org/wikipedia/commons/3/38/Terminator_2.png\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-02-18T12:33:53.454887Z",
     "start_time": "2021-02-18T12:33:52.218227Z"
    },
    "init_cell": true,
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "%reset -f\n",
    "from IPython import display\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "# produce vector inline graphics\n",
    "from IPython.display import set_matplotlib_formats\n",
    "set_matplotlib_formats('svg')\n",
    "from weka.core import dataset\n",
    "import weka.core.jvm as jvm\n",
    "from weka.core.converters import Loader\n",
    "from weka.classifiers import Classifier, Evaluation, SingleClassifierEnhancer\n",
    "from sklearn import ensemble, tree\n",
    "from weka.core.classes import Random\n",
    "from weka.core.classes import complete_classname\n",
    "from sklearn import ensemble\n",
    "from scipy.io import arff\n",
    "import urllib.request\n",
    "import io"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this notebook, we will try to build the best machine to classify the image segmentation dataset:\n",
    "- `segment-challenge.arff` for training, and\n",
    "- `segment-test.arff` for testing."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Individual Classification Algorithms"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Weka provides a KnowledgeFlow interface to flow data through a learning algorithm. The following is a demo for training and testing a J48 decision tree."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-02-18T12:33:53.462323Z",
     "start_time": "2021-02-18T12:33:53.456811Z"
    },
    "init_cell": true,
    "tags": [
     "hide-input"
    ]
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "        <iframe\n",
       "            width=\"805\"\n",
       "            height=\"450\"\n",
       "            src=\"https://cityuhk-lms.ap.panopto.com/Panopto/Pages/Embed.aspx?id=3f33d95a-c5c2-4893-925b-acd10064acec&autoplay=false&offerviewer=true&showtitle=true&showbrand=false&start=0&interactivity=all\"\n",
       "            frameborder=\"0\"\n",
       "            allowfullscreen\n",
       "        ></iframe>\n",
       "        "
      ],
      "text/plain": [
       "<IPython.lib.display.IFrame at 0x7f0bf44b7ed0>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "display.IFrame(src=\"https://cityuhk-lms.ap.panopto.com/Panopto/Pages/Embed.aspx?id=3f33d95a-c5c2-4893-925b-acd10064acec&autoplay=false&offerviewer=true&showtitle=true&showbrand=false&start=0&interactivity=all\", height=450, width=805)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Similar to the other interfaces, the evaluation results can be saved to files as demonstrated below. You may also load an existing template using a button in the toolbar on the top right-hand corner, as illustrated in the video below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-02-18T12:33:53.477549Z",
     "start_time": "2021-02-18T12:33:53.464337Z"
    },
    "init_cell": true,
    "tags": [
     "hide-input"
    ]
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "        <iframe\n",
       "            width=\"805\"\n",
       "            height=\"450\"\n",
       "            src=\"https://cityuhk-lms.ap.panopto.com/Panopto/Pages/Embed.aspx?id=e60913e2-128b-4e40-962d-acd1006b8347&autoplay=false&offerviewer=true&showtitle=true&showbrand=false&start=0&interactivity=all\"\n",
       "            frameborder=\"0\"\n",
       "            allowfullscreen\n",
       "        ></iframe>\n",
       "        "
      ],
      "text/plain": [
       "<IPython.lib.display.IFrame at 0x7f0bc4d92e90>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "display.IFrame(src=\"https://cityuhk-lms.ap.panopto.com/Panopto/Pages/Embed.aspx?id=e60913e2-128b-4e40-962d-acd1006b8347&autoplay=false&offerviewer=true&showtitle=true&showbrand=false&start=0&interactivity=all\", height=450, width=805)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Unlike the other interfaces, KnowledgeFlow interface can train a classifier incrementally as more and more data becomes available. For more details, refer to the manual [here](https://www.cs.waikato.ac.nz/ml/weka/Witten_et_al_2016_appendix.pdf) and the [video tutorial](https://www.futurelearn.com/info/courses/more-data-mining-with-weka/0/steps/29106) by Witten."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Furthermore, unlike the Explorer interface, one can flow data through multiple classification algorithms simultaneously as illustrated below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-02-18T12:33:53.489521Z",
     "start_time": "2021-02-18T12:33:53.481025Z"
    },
    "init_cell": true,
    "tags": [
     "hide-input"
    ]
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "        <iframe\n",
       "            width=\"805\"\n",
       "            height=\"450\"\n",
       "            src=\"https://cityuhk-lms.ap.panopto.com/Panopto/Pages/Embed.aspx?id=0d3c11b4-7809-45c7-a208-acd1006ea2f1&autoplay=false&offerviewer=true&showtitle=true&showbrand=false&start=0&interactivity=all\"\n",
       "            frameborder=\"0\"\n",
       "            allowfullscreen\n",
       "        ></iframe>\n",
       "        "
      ],
      "text/plain": [
       "<IPython.lib.display.IFrame at 0x7f0bc4ce9490>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "display.IFrame(src=\"https://cityuhk-lms.ap.panopto.com/Panopto/Pages/Embed.aspx?id=0d3c11b4-7809-45c7-a208-acd1006ea2f1&autoplay=false&offerviewer=true&showtitle=true&showbrand=false&start=0&interactivity=all\",  height=450, width=805)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Exercise** Follow the video above to add other classifiers: `IBk`, `PART`, and `JRIP`. Record their fractional accuracies in the dictionary `performance` as follows:\n",
    "\n",
    "```Python\n",
    "performance = {'J48': 0.961728,\n",
    "               'IBk': ___,\n",
    "               'ZeroR': ___,\n",
    "               'OneR': ___,\n",
    "               'PART': ___,\n",
    "               'JRIP': ___}\n",
    "```\n",
    "\n",
    "Use the default parameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-02-18T09:17:59.812000Z",
     "start_time": "2021-02-18T09:17:59.803501Z"
    },
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "4fdc0f9a1b555aa8fd103a684fe9a4cc",
     "grade": false,
     "grade_id": "kf",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# YOUR CODE HERE\n",
    "raise NotImplementedError()\n",
    "performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-02-18T09:19:05.635748Z",
     "start_time": "2021-02-18T09:19:05.631488Z"
    },
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "9985b8f945cb9e70f0e13f27579bfedd",
     "grade": true,
     "grade_id": "test-kf",
     "locked": true,
     "points": 1,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# tests"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ensemble Methods"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we use the ensemble methods implemented in scikit-learn and Weka to train armies of classifiers."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Preparation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following load the data for scikit-learn."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-02-18T10:27:11.464579Z",
     "start_time": "2021-02-18T10:27:10.248714Z"
    }
   },
   "outputs": [],
   "source": [
    "def load_url(url):\n",
    "    ftpstream = urllib.request.urlopen(url)\n",
    "    df = pd.DataFrame(arff.loadarff(io.StringIO(ftpstream.read().decode('utf-8')))[0])\n",
    "    return df.loc[:,lambda df: ~df.columns.isin(['class'])], df['class'].astype(str)\n",
    "\n",
    "weka_data_path = 'https://raw.githubusercontent.com/Waikato/weka-3.8/master/wekadocs/data/'\n",
    "X_train, Y_train = load_url(weka_data_path + 'segment-challenge.arff')\n",
    "X_test, Y_test = load_url(weka_data_path + 'segment-test.arff')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following loads the data for `python-weka-wrapper`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-02-18T10:27:13.136582Z",
     "start_time": "2021-02-18T10:27:12.458323Z"
    }
   },
   "outputs": [],
   "source": [
    "jvm.start()\n",
    "loader = Loader(classname=\"weka.core.converters.ArffLoader\")\n",
    "trainset = loader.load_url(\n",
    "    weka_data_path +\n",
    "    'segment-challenge.arff')  # use load_file to load from file instead\n",
    "trainset.class_is_last()\n",
    "\n",
    "testset = loader.load_url(weka_data_path + 'segment-test.arff')\n",
    "testset.class_is_last()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random Forest"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following trains a random forest of 10 decision trees with maximum depth 5."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-02-18T10:51:19.577690Z",
     "start_time": "2021-02-18T10:51:19.542168Z"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn import ensemble\n",
    "\n",
    "RF = ensemble.RandomForestClassifier(max_depth=5, \n",
    "                                     n_estimators=10, \n",
    "                                     random_state=0)\n",
    "RF.fit(X_train, Y_train)\n",
    "print(f'Accuracy: {RF.score(X_test, Y_test):.4g}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Exercise** Complete the pandas `DataFrame` `RF_df` in the following cell by filling in the accuracies (as floating point numbers) for different `n_estimators` and `max_depth`. Use `random_state = 0`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-02-18T11:11:58.436546Z",
     "start_time": "2021-02-18T11:11:47.732916Z"
    },
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "e492dbbedd482cfa3aea9c44c84b2ab2",
     "grade": false,
     "grade_id": "rf",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "depth_list = [1, 2, 3, 5, 10, 20]\n",
    "n_estimators_list = [1, 2, 3, 5, 10, 20, 30, 50, 100, 200, 300]\n",
    "RF_df = pd.DataFrame(columns=[f'max_depth={max_depth}' for max_depth in depth_list], dtype=float)\n",
    "RF_df.insert(0, 'n_estimators', n_estimators_list)\n",
    "# YOUR CODE HERE\n",
    "raise NotImplementedError()\n",
    "display.display(RF_df.round(4))\n",
    "\n",
    "plt.figure(figsize=(8, 5))\n",
    "for col in RF_df.columns[1:]:\n",
    "    plt.plot(RF_df['n_estimators'],\n",
    "             RF_df[col],\n",
    "             label=col,\n",
    "             marker='o')\n",
    "plt.legend()\n",
    "plt.xlabel('n_estimators')\n",
    "plt.ylabel('Accuracies')\n",
    "plt.title(r'Random forest of different sizes and depths')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-02-18T10:57:56.172275Z",
     "start_time": "2021-02-18T10:57:56.147737Z"
    },
    "code_folding": [
     0
    ],
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "abbec6c48885083db55e85ee80774fff",
     "grade": true,
     "grade_id": "test-rf",
     "locked": true,
     "points": 1,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# tests"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To train a random forest of 10 decision trees with maximum depth 5 using `python-weka-wrapper`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-02-18T10:54:26.591412Z",
     "start_time": "2021-02-18T10:54:26.555231Z"
    }
   },
   "outputs": [],
   "source": [
    "RF = Classifier(classname=\"weka.classifiers.trees.RandomForest\")\n",
    "RF.options = ['-I', '10',\n",
    "              '-depth', '5',\n",
    "              '-S', '1']\n",
    "RF.build_classifier(trainset)\n",
    "evl = Evaluation(testset)\n",
    "evl.test_model(RF, testset)\n",
    "print(f'Accuracy {evl.percent_correct/100:.4g}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Exercise** Repeat the previous exercise but with Weka instead. Use a random seed of 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-02-18T11:06:47.716793Z",
     "start_time": "2021-02-18T11:06:36.702308Z"
    },
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "9ae43fc9ee2fe5338cee7bb76d4e66ab",
     "grade": false,
     "grade_id": "rf-weka",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "depth_list = [1, 2, 3, 5, 10, 20]\n",
    "n_estimators_list = [1, 2, 3, 5, 10, 20, 30, 50, 100, 200, 300]\n",
    "RF_df = pd.DataFrame(columns=[f'max_depth={max_depth}' for max_depth in depth_list], dtype=float)\n",
    "RF_df.insert(0, 'n_estimators', n_estimators_list)\n",
    "# YOUR CODE HERE\n",
    "raise NotImplementedError()\n",
    "display.display(RF_df.round(4))\n",
    "\n",
    "plt.figure(figsize=(8, 5))\n",
    "for col in RF_df.columns[1:]:\n",
    "    plt.plot(RF_df['n_estimators'],\n",
    "             RF_df[col],\n",
    "             label=col,\n",
    "             marker='o')\n",
    "plt.legend()\n",
    "plt.xlabel('n_estimators')\n",
    "plt.ylabel('Accuracies')\n",
    "plt.title(r'Random forest of different sizes and depths')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-02-18T11:06:28.683273Z",
     "start_time": "2021-02-18T11:06:28.541160Z"
    },
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "25b6fb9c7ec1cbb50444c23e5c3cbc7c",
     "grade": true,
     "grade_id": "test-rf-weka",
     "locked": true,
     "points": 1,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# tests"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Exercise** What are the best choices of `n_estimators` and `max_depth`?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "23969d8ed907bcab86313621f2e0383a",
     "grade": true,
     "grade_id": "rf-best",
     "locked": false,
     "points": 1,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "source": [
    "YOUR ANSWER HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### AdaBoost"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To train AdaBoost with 10 decision trees of maximum depth 5:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-02-18T11:25:03.198449Z",
     "start_time": "2021-02-18T11:25:03.038566Z"
    }
   },
   "outputs": [],
   "source": [
    "ADB = ensemble.AdaBoostClassifier(base_estimator=tree.DecisionTreeClassifier(max_depth=5), n_estimators=10, random_state=0)\n",
    "ADB.fit(X_train, Y_train)\n",
    "print(f'Accuracy: {ADB.score(X_test, Y_test):.4g}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Exercise** Complete the pandas `DataFrame` `ADB_df` in the following cell by filling in the accuracies (as floating point numbers) for different `n_estimators` and `max_depth`. Use `random_state = 0`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-02-18T11:37:24.883747Z",
     "start_time": "2021-02-18T11:37:13.937438Z"
    },
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "e0fc7bbbedcc20e62bf0466fd5f3f27f",
     "grade": false,
     "grade_id": "adb",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "depth_list = [1, 2, 3, 5, 10]\n",
    "n_estimators_list = [1, 2, 3, 5, 10, 20, 30, 50, 100]\n",
    "ADB_df = pd.DataFrame(columns=[f'max_depth={max_depth}' for max_depth in depth_list], dtype=float)\n",
    "ADB_df.insert(0, 'n_estimators', n_estimators_list)\n",
    "# YOUR CODE HERE\n",
    "raise NotImplementedError()\n",
    "display.display(ADB_df.round(4))\n",
    "\n",
    "plt.figure(figsize=(8, 5))\n",
    "for col in ADB_df.columns[1:]:\n",
    "    plt.plot(ADB_df['n_estimators'],\n",
    "             ADB_df[col],\n",
    "             label=col,\n",
    "             marker='o')\n",
    "plt.legend()\n",
    "plt.xlabel('n_estimators')\n",
    "plt.ylabel('Accuracies')\n",
    "plt.title(r'Adaboost of different sizes and depths')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-02-18T11:36:00.424280Z",
     "start_time": "2021-02-18T11:36:00.406173Z"
    },
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "f9b12b581b292788fbd0a7515dc76c61",
     "grade": true,
     "grade_id": "test-adb",
     "locked": true,
     "points": 1,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# tests"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To train AdaBoost with 10 decision trees of maximum depth 5 using `python-weka-wrapper`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-02-18T11:50:24.752591Z",
     "start_time": "2021-02-18T11:50:24.382443Z"
    }
   },
   "outputs": [],
   "source": [
    "REPTree = Classifier(classname=\"weka.classifiers.trees.REPTree\")\n",
    "REPTree.options = ['-L', '5']\n",
    "ADB = SingleClassifierEnhancer(classname=\"weka.classifiers.meta.AdaBoostM1\")\n",
    "ADB.options=['-I', '10',\n",
    "             '-S', '1']\n",
    "ADB.classifier = REPTree\n",
    "ADB.build_classifier(trainset)\n",
    "evl = Evaluation(testset)\n",
    "evl.test_model(ADB, testset)\n",
    "print(f'Accuracy {evl.percent_correct/100:.4g}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Exercise** Repeat the previous exercise but with Weka instead. Use a random seed of 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-02-18T11:57:55.042969Z",
     "start_time": "2021-02-18T11:57:48.361265Z"
    },
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "f1145f559ad2ddd0abe9a6e970351ce2",
     "grade": false,
     "grade_id": "adb-weka",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "depth_list = [1, 2, 3, 5, 10]\n",
    "n_estimators_list = [1, 2, 3, 5, 10, 20, 30, 50, 100]\n",
    "ADB_df = pd.DataFrame(columns=[f'max_depth={max_depth}' for max_depth in depth_list], dtype=float)\n",
    "ADB_df.insert(0, 'n_estimators', n_estimators_list)\n",
    "# YOUR CODE HERE\n",
    "raise NotImplementedError()\n",
    "display.display(ADB_df.round(4))\n",
    "\n",
    "plt.figure(figsize=(8, 5))\n",
    "for col in ADB_df.columns[1:]:\n",
    "    plt.plot(ADB_df['n_estimators'],\n",
    "             ADB_df[col],\n",
    "             label=col,\n",
    "             marker='o')\n",
    "plt.legend()\n",
    "plt.xlabel('n_estimators')\n",
    "plt.ylabel('Accuracies')\n",
    "plt.title(r'Adaboost of different sizes and depths')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-02-18T11:57:19.926947Z",
     "start_time": "2021-02-18T11:57:19.910613Z"
    },
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "1c90a31c6b4489d5799c10c4cdab9646",
     "grade": true,
     "grade_id": "test-adb-weka",
     "locked": true,
     "points": 1,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# tests"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Exercise** Which ensemble method is better, Adaboost or random forest? Why?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "e676cdf3cbec4928fa23ca7795ce1e09",
     "grade": true,
     "grade_id": "rf-vs-adb",
     "locked": false,
     "points": 1,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "source": [
    "YOUR ANSWER HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Optional Challenge"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Train your own classifier to achieve the highest possible accuracies. You may:\n",
    "- choose different classification algorithms or ensemble methods such as Bagging, Stacking, Voting, XGBoost, etc.\n",
    "- tune the hyper-parameters manually or automatically using `GridSearchCV` in `scikit-learn` or `CVParameterSelection` in Weka.\n",
    "\n",
    "Post your model and results on [Canvas](https://canvas.cityu.edu.hk/courses/39808/discussion_topics/306324) to compete with others."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following is an example using XGBoost with its default parameters.\n",
    "```Python\n",
    "import xgboost\n",
    "XGB = xgboost.XGBClassifier()\n",
    "XGB.fit(X_train, Y_train)\n",
    "print(f'Accuracy: {XGB.score(X_test, Y_test):.4g')\n",
    "```"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.7",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  },
  "rise": {
   "enable_chalkboard": true,
   "scroll": true,
   "theme": "white"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": true,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

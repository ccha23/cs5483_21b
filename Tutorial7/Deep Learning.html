
<!DOCTYPE html>

<html>
  <head>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" />
    <title>Deep Learning &#8212; CS5483</title>
    
  <link rel="stylesheet" href="../_static/css/index.73d71520a4ca3b99cfee5594769eaaae.css">

    
  <link rel="stylesheet"
    href="../_static/vendor/fontawesome/5.13.0/css/all.min.css">
  <link rel="preload" as="font" type="font/woff2" crossorigin
    href="../_static/vendor/fontawesome/5.13.0/webfonts/fa-solid-900.woff2">
  <link rel="preload" as="font" type="font/woff2" crossorigin
    href="../_static/vendor/fontawesome/5.13.0/webfonts/fa-brands-400.woff2">

    
      
  <link rel="stylesheet"
    href="../_static/vendor/open-sans_all/1.44.1/index.css">
  <link rel="stylesheet"
    href="../_static/vendor/lato_latin-ext/1.44.1/index.css">

    
    <link rel="stylesheet" href="../_static/pygments.css" type="text/css" />
    <link rel="stylesheet" href="../_static/sphinx-book-theme.40e2e510f6b7d1648584402491bb10fe.css" type="text/css" />
    <link rel="stylesheet" type="text/css" href="../_static/togglebutton.css" />
    <link rel="stylesheet" type="text/css" href="../_static/copybutton.css" />
    <link rel="stylesheet" type="text/css" href="../_static/mystnb.css" />
    <link rel="stylesheet" type="text/css" href="../_static/sphinx-thebe.css" />
    <link rel="stylesheet" type="text/css" href="../_static/panels-main.c949a650a448cc0ae9fd3441c0e17fb0.css" />
    <link rel="stylesheet" type="text/css" href="../_static/panels-variables.06eb56fa6e07937060861dad626602ad.css" />
    
  <link rel="preload" as="script" href="../_static/js/index.3da636dd464baa7582d2.js">

    <script id="documentation_options" data-url_root="../" src="../_static/documentation_options.js"></script>
    <script src="../_static/jquery.js"></script>
    <script src="../_static/underscore.js"></script>
    <script src="../_static/doctools.js"></script>
    <script src="../_static/togglebutton.js"></script>
    <script src="../_static/clipboard.min.js"></script>
    <script src="../_static/copybutton.js"></script>
    <script async="async" kind="hypothesis" src="https://hypothes.is/embed.js"></script>
    <script kind="utterances">

    var commentsRunWhenDOMLoaded = cb => {
    if (document.readyState != 'loading') {
        cb()
    } else if (document.addEventListener) {
        document.addEventListener('DOMContentLoaded', cb)
    } else {
        document.attachEvent('onreadystatechange', function() {
        if (document.readyState == 'complete') cb()
        })
    }
}

var addUtterances = () => {
    var script = document.createElement("script");
    script.type = "text/javascript";
    script.src = "https://utteranc.es/client.js";
    script.async = "async";

    script.setAttribute("repo", "ccha23/cs5483");
    script.setAttribute("issue-term", "pathname");
    script.setAttribute("theme", "github-light");
    script.setAttribute("label", "ðŸ’¬ comment");
    script.setAttribute("crossorigin", "anonymous");

    sections = document.querySelectorAll("div.section");
    if (sections !== null) {
        section = sections[sections.length-1];
        section.appendChild(script);
    }
}
commentsRunWhenDOMLoaded(addUtterances);
</script>
    <script >var togglebuttonSelector = '.toggle, .admonition.dropdown, .tag_hide_input div.cell_input, .tag_hide-input div.cell_input, .tag_hide_output div.cell_output, .tag_hide-output div.cell_output, .tag_hide_cell.cell, .tag_hide-cell.cell';</script>
    <script src="../_static/sphinx-book-theme.d31b09fe5c1d09cb49b26a786de4a05d.js"></script>
    <script async="async" src="https://unpkg.com/thebelab@latest/lib/index.js"></script>
    <script >
        const thebe_selector = ".thebe,.cell"
        const thebe_selector_input = "pre,.cell_input div.highlight"
        const thebe_selector_output = ".output,.cell_output"
    </script>
    <script async="async" src="../_static/sphinx-thebe.js"></script>
    <script async="async" src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>
    <script type="text/x-mathjax-config">MathJax.Hub.Config({"tex2jax": {"inlineMath": [["\\(", "\\)"]], "displayMath": [["\\[", "\\]"]], "processRefs": false, "processEnvironments": false}})</script>
    <link rel="index" title="Index" href="../genindex.html" />
    <link rel="search" title="Search" href="../search.html" />
    <link rel="next" title="Partitional Clustering" href="../Tutorial8/Partitional%20Clustering.html" />
    <link rel="prev" title="Machine vs Machine" href="../Tutorial6/Machine%20vs%20Machine.html" />

    <meta name="viewport" content="width=device-width, initial-scale=1" />
    <meta name="docsearch:language" content="en" />



  </head>
  <body data-spy="scroll" data-target="#bd-toc-nav" data-offset="80">
    

    <div class="container-xl">
      <div class="row">
          
<div class="col-12 col-md-3 bd-sidebar site-navigation show" id="site-navigation">
    
        <div class="navbar-brand-box">
<a class="navbar-brand text-wrap" href="../index.html">
  
  <img src="../_static/logo.svg" class="logo" alt="logo">
  
  
  <h1 class="site-logo" id="site-title">CS5483</h1>
  
</a>
</div><form class="bd-search d-flex align-items-center" action="../search.html" method="get">
  <i class="icon fas fa-search"></i>
  <input type="search" class="form-control" name="q" id="search-input" placeholder="Search this book..." aria-label="Search this book..." autocomplete="off" >
</form>
<nav class="bd-links" id="bd-docs-nav" aria-label="Main navigation">
    <ul class="nav sidenav_l1">
 <li class="toctree-l1">
  <a class="reference internal" href="../README.html">
   Data Warehousing and Data Mining
  </a>
 </li>
</ul>
<p class="caption collapsible-parent">
 <span class="caption-text">
  Tutorial 1
 </span>
</p>
<ul class="nav sidenav_l1">
 <li class="toctree-l1">
  <a class="reference internal" href="../Tutorial1/Setup.html">
   Setup
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../Tutorial1/Data%20Files.html">
   Data Files
  </a>
 </li>
</ul>
<p class="caption collapsible-parent">
 <span class="caption-text">
  Tutorial 2
 </span>
</p>
<ul class="nav sidenav_l1">
 <li class="toctree-l1">
  <a class="reference internal" href="../Tutorial2/Estimation%20from%20Samples.html">
   Estimation from Samples
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../Tutorial2/Evaluation%20using%20Weka.html">
   Evaluation using Weka
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../Tutorial2/Evaluation%20with%20scikit-learn.html">
   Evaluation with scikit-learn
  </a>
 </li>
</ul>
<p class="caption collapsible-parent">
 <span class="caption-text">
  Tutorial 3
 </span>
</p>
<ul class="nav sidenav_l1">
 <li class="toctree-l1">
  <a class="reference internal" href="../Tutorial3/Information%20Quantities%20for%20Decision%20Tree%20Induction.html">
   Information Quantities for Decision Tree Induction
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../Tutorial3/Man%20vs%20Machine.html">
   Man vs Machine
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../Tutorial3/Decision%20Tree%20Induction%20with%20scikit-learn.html">
   Decision Tree Induction with scikit-learn
  </a>
 </li>
</ul>
<p class="caption collapsible-parent">
 <span class="caption-text">
  Tutorial 4
 </span>
</p>
<ul class="nav sidenav_l1">
 <li class="toctree-l1">
  <a class="reference internal" href="../Tutorial4/Different%20Classifiers%20with%20Weka.html">
   Different Classifiers with Weka
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../Tutorial4/Different%20Classifiers%20with%20scikit-learn.html">
   Different Classifiers with scikit-learn
  </a>
 </li>
</ul>
<p class="caption collapsible-parent">
 <span class="caption-text">
  Project 1
 </span>
</p>
<ul class="nav sidenav_l1">
 <li class="toctree-l1">
  <a class="reference internal" href="../Project1/Project1.html">
   Project 1
  </a>
 </li>
</ul>
<p class="caption collapsible-parent">
 <span class="caption-text">
  Tutorial 5
 </span>
</p>
<ul class="nav sidenav_l1">
 <li class="toctree-l1">
  <a class="reference internal" href="../Tutorial5/Evaluation%20for%20Skewed%20Dataset.html">
   Evaluation for Skewed Dataset
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../Tutorial5/Training%20with%20Skewed%20Dataset.html">
   Training with Skewed Dataset
  </a>
 </li>
</ul>
<p class="caption collapsible-parent">
 <span class="caption-text">
  Tutorial 6
 </span>
</p>
<ul class="nav sidenav_l1">
 <li class="toctree-l1">
  <a class="reference internal" href="../Tutorial6/Machine%20vs%20Machine.html">
   Machine vs Machine
  </a>
 </li>
</ul>
<p class="caption collapsible-parent">
 <span class="caption-text">
  Tutorial 7
 </span>
</p>
<ul class="current nav sidenav_l1">
 <li class="toctree-l1 current active">
  <a class="current reference internal" href="#">
   Deep Learning
  </a>
 </li>
</ul>
<p class="caption collapsible-parent">
 <span class="caption-text">
  Tutorial 8
 </span>
</p>
<ul class="nav sidenav_l1">
 <li class="toctree-l1">
  <a class="reference internal" href="../Tutorial8/Partitional%20Clustering.html">
   Partitional Clustering
  </a>
 </li>
</ul>
<p class="caption collapsible-parent">
 <span class="caption-text">
  Tutorial 9
 </span>
</p>
<ul class="nav sidenav_l1">
 <li class="toctree-l1">
  <a class="reference internal" href="../Tutorial9/Hierarchical%20Clustering.html">
   Hierarchical Clustering
  </a>
 </li>
</ul>

</nav> <!-- To handle the deprecated key -->

<div class="navbar_extra_footer">
  Powered by <a href="https://jupyterbook.org">Jupyter Book</a>
</div>

</div>


          


          
<main class="col py-md-3 pl-md-4 bd-content overflow-auto" role="main">
    
    <div class="row topbar fixed-top container-xl">
    <div class="col-12 col-md-3 bd-topbar-whitespace site-navigation show">
    </div>
    <div class="col pl-2 topbar-main">
        
        <button id="navbar-toggler" class="navbar-toggler ml-0" type="button" data-toggle="collapse"
            data-toggle="tooltip" data-placement="bottom" data-target=".site-navigation" aria-controls="navbar-menu"
            aria-expanded="true" aria-label="Toggle navigation" aria-controls="site-navigation"
            title="Toggle navigation" data-toggle="tooltip" data-placement="left">
            <i class="fas fa-bars"></i>
            <i class="fas fa-arrow-left"></i>
            <i class="fas fa-arrow-up"></i>
        </button>
        
        
<div class="dropdown-buttons-trigger">
    <button id="dropdown-buttons-trigger" class="btn btn-secondary topbarbtn" aria-label="Download this page"><i
            class="fas fa-download"></i></button>

    <div class="dropdown-buttons">
        <!-- ipynb file if we had a myst markdown file -->
        
        <!-- Download raw file -->
        <a class="dropdown-buttons" href="../_sources/Tutorial7/Deep Learning.ipynb"><button type="button"
                class="btn btn-secondary topbarbtn" title="Download source file" data-toggle="tooltip"
                data-placement="left">.ipynb</button></a>
        <!-- Download PDF via print -->
        <button type="button" id="download-print" class="btn btn-secondary topbarbtn" title="Print to PDF"
            onClick="window.print()" data-toggle="tooltip" data-placement="left">.pdf</button>
    </div>
</div>

        <!-- Source interaction buttons -->


        <!-- Full screen (wrap in <a> to have style consistency -->
        <a class="full-screen-button"><button type="button" class="btn btn-secondary topbarbtn" data-toggle="tooltip"
                data-placement="bottom" onclick="toggleFullScreen()" aria-label="Fullscreen mode"
                title="Fullscreen mode"><i
                    class="fas fa-expand"></i></button></a>

        <!-- Launch buttons -->

<div class="dropdown-buttons-trigger">
    <button id="dropdown-buttons-trigger" class="btn btn-secondary topbarbtn"
        aria-label="Launch interactive content"><i class="fas fa-rocket"></i></button>
    <div class="dropdown-buttons">
        
        
        <a class="jupyterhub-button" href="https://ltjh.cs.cityu.edu.hk/hub/user-redirect/git-pull?repo=https://github.com/ccha23/cs5483&urlpath=tree/cs5483/Tutorial7/Deep Learning.ipynb&branch=main"><button type="button"
                class="btn btn-secondary topbarbtn" title="Launch JupyterHub" data-toggle="tooltip"
                data-placement="left"><img class="jupyterhub-button-logo"
                    src="../_static/images/logo_jupyterhub.svg"
                    alt="Interact on JupyterHub">JupyterHub</button></a>
        
        
        <a class="colab-button" href="https://colab.research.google.com/github/ccha23/cs5483/blob/main/Tutorial7/Deep Learning.ipynb"><button type="button" class="btn btn-secondary topbarbtn"
                title="Launch Colab" data-toggle="tooltip" data-placement="left"><img class="colab-button-logo"
                    src="../_static/images/logo_colab.png"
                    alt="Interact on Colab">Colab</button></a>
        
        <button type="button" class="btn btn-secondary topbarbtn"
            onclick="initThebeSBT()" title="Launch Thebe" data-toggle="tooltip" data-placement="left"><i
                class="fas fa-play"></i><span style="margin-left: .4em;">Live Code</span></button>
        
    </div>
</div>

    </div>

    <!-- Table of contents -->
    <div class="d-none d-md-block col-md-2 bd-toc show">
        
        <div class="tocsection onthispage pt-5 pb-3">
            <i class="fas fa-list"></i> Contents
        </div>
        <nav id="bd-toc-nav">
            <ul class="nav section-nav flex-column">
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#introduction">
   Introduction
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#preliminaries">
   Preliminaries
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#classification-problem">
   Classification Problem
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#data-preparation">
   Data Preparation
  </a>
  <ul class="nav section-nav flex-column">
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#load-the-dataset">
     Load the dataset
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#show-an-example">
     Show an example
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#preprocess-the-data">
     Preprocess the data
    </a>
   </li>
  </ul>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#training-and-testing">
   Training and Testing
  </a>
  <ul class="nav section-nav flex-column">
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#define-the-neural-network-architecture">
     Define the neural network architecture
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#train-and-validate">
     Train and validate
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#log-the-results">
     Log the results
    </a>
   </li>
  </ul>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#deployment">
   Deployment
  </a>
 </li>
</ul>

        </nav>
        
    </div>
</div>
    <div id="main-content" class="row">
        <div class="col-12 col-md-9 pl-md-3 pr-md-0">
        
              <div>
                
  <div class="section" id="deep-learning">
<h1>Deep Learning<a class="headerlink" href="#deep-learning" title="Permalink to this headline">Â¶</a></h1>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="o">%</span><span class="k">reset</span> -f
<span class="o">%</span><span class="k">load_ext</span> tensorboard
<span class="o">%</span><span class="k">matplotlib</span> inline
<span class="kn">import</span> <span class="nn">jupyter_manim</span>
<span class="kn">from</span> <span class="nn">manimlib.imports</span> <span class="kn">import</span> <span class="o">*</span>
<span class="kn">import</span> <span class="nn">pprint</span> <span class="k">as</span> <span class="nn">pp</span>
<span class="kn">import</span> <span class="nn">tensorflow_datasets</span> <span class="k">as</span> <span class="nn">tfds</span>
<span class="kn">import</span> <span class="nn">tensorflow.compat.v2</span> <span class="k">as</span> <span class="nn">tf</span>
<span class="kn">import</span> <span class="nn">tensorflow_addons</span> <span class="k">as</span> <span class="nn">tfa</span>
<span class="kn">import</span> <span class="nn">os</span><span class="o">,</span> <span class="nn">datetime</span><span class="o">,</span> <span class="nn">pytz</span>
<span class="kn">import</span> <span class="nn">tensorboard</span> <span class="k">as</span> <span class="nn">tb</span>
<span class="kn">from</span> <span class="nn">matplotlib</span> <span class="kn">import</span> <span class="n">pyplot</span> <span class="k">as</span> <span class="n">plt</span>
<span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>
<span class="kn">from</span> <span class="nn">IPython</span> <span class="kn">import</span> <span class="n">display</span>
<span class="kn">import</span> <span class="nn">matplotlib.pyplot</span> <span class="k">as</span> <span class="nn">plt</span>
<span class="c1"># produce vector inline graphics</span>
<span class="kn">from</span> <span class="nn">IPython.display</span> <span class="kn">import</span> <span class="n">set_matplotlib_formats</span>
<span class="n">set_matplotlib_formats</span><span class="p">(</span><span class="s1">&#39;svg&#39;</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<div class="section" id="introduction">
<h2>Introduction<a class="headerlink" href="#introduction" title="Permalink to this headline">Â¶</a></h2>
<p>In this notebook, we will train the following classifier using deep learning:</p>
<ol class="simple">
<li><p>Handwrite a digit from 0, â€¦, 9.</p></li>
<li><p>Click predict to see if the app can recognize the digit.</p></li>
</ol>
<div class="cell tag_hide-input docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">display</span><span class="o">.</span><span class="n">IFrame</span><span class="p">(</span><span class="n">src</span><span class="o">=</span><span class="s2">&quot;https://www.cs.cityu.edu.hk/~ccha23/mnist/&quot;</span><span class="p">,</span> <span class="n">width</span><span class="o">=</span><span class="mi">805</span><span class="p">,</span> <span class="n">height</span><span class="o">=</span><span class="mi">450</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_html">
<iframe
    width="805"
    height="450"
    src="https://www.cs.cityu.edu.hk/~ccha23/mnist/"
    frameborder="0"
    allowfullscreen
></iframe>
</div></div>
</div>
<p><strong>What is deep learning?</strong></p>
<p><a class="reference external" href="https://en.wikipedia.org/wiki/Deep_learning">Deep learning</a> is a technique of training a neural network with many layers of computational units called neurons. The following videos showcase some interesting applications of the technique.</p>
<div class="cell tag_hide-input docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">display</span><span class="o">.</span><span class="n">IFrame</span><span class="p">(</span><span class="n">src</span><span class="o">=</span><span class="s2">&quot;https://slides.com/ccha23/dl_intro/embed&quot;</span><span class="p">,</span> <span class="n">width</span><span class="o">=</span><span class="mi">805</span><span class="p">,</span> <span class="n">height</span><span class="o">=</span><span class="mi">450</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_html">
<iframe
    width="805"
    height="450"
    src="https://slides.com/ccha23/dl_intro/embed"
    frameborder="0"
    allowfullscreen
></iframe>
</div></div>
</div>
<p><strong>How to train a neural network?</strong></p>
<p>We can visualize the training process in the following application, which trains a neural network that predicts the color of a given point when given its coordinate <span class="math notranslate nohighlight">\((x_1,x_2)\)</span>.</p>
<ul class="simple">
<li><p>Choose a data set from the <code class="docutils literal notranslate"><span class="pre">DATA</span></code> column.</p></li>
<li><p>Click the <code class="docutils literal notranslate"><span class="pre">play</span></code> button to start training the network.</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">Epoch</span></code> is the number of times a neural network is trained iteratively using the data selected.</p></li>
<li><p>In the <code class="docutils literal notranslate"><span class="pre">OUTPUT</span></code> column,</p>
<ul>
<li><p>points in the blue region are predicted blue, and</p></li>
<li><p>points in the orange region are predicted orange.</p></li>
</ul>
</li>
</ul>
<div class="cell tag_hide-input docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">display</span><span class="o">.</span><span class="n">IFrame</span><span class="p">(</span><span class="n">src</span><span class="o">=</span><span class="s2">&quot;https://www.cs.cityu.edu.hk/~ccha23/playground&quot;</span><span class="p">,</span> <span class="n">width</span><span class="o">=</span><span class="mi">900</span><span class="p">,</span> <span class="n">height</span><span class="o">=</span><span class="mi">800</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_html">
<iframe
    width="900"
    height="800"
    src="https://www.cs.cityu.edu.hk/~ccha23/playground"
    frameborder="0"
    allowfullscreen
></iframe>
</div></div>
</div>
<p>The above app is a slight modification of the open source project <a class="reference external" href="https://playground.tensorflow.org">Tensorflow Playground</a> with the additional features that:</p>
<ul class="simple">
<li><p>You can save your configuration to the browser session by clicking the button <code class="docutils literal notranslate"><span class="pre">Save</span> <span class="pre">to</span> <span class="pre">browser</span> <span class="pre">session</span></code>. If you reopen the browser, it will load your previously saved configuration automatically.</p></li>
<li><p>You can reset the configuration by clicking the <code class="docutils literal notranslate"><span class="pre">reset</span></code> button.</p></li>
<li><p>The last button copies the permalink to your configuration to the clipboard. You can save multiple configurations and share them by keeping the permalinks.</p></li>
</ul>
<p>For instance, the following uses the permalink to initialize the simplest neural network for the linearly separable data:</p>
<div class="cell tag_hide-input docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">display</span><span class="o">.</span><span class="n">IFrame</span><span class="p">(</span><span class="n">src</span><span class="o">=</span><span class="s2">&quot;https://www.cs.cityu.edu.hk/~ccha23/playground/#activation=linear&amp;batchSize=10&amp;dataset=gauss&amp;regDataset=reg-plane&amp;learningRate=0.03&amp;regularizationRate=0&amp;noise=0&amp;networkShape=&amp;seed=0.15891&amp;showTestData=false&amp;discretize=false&amp;percTrainData=50&amp;x=true&amp;y=true&amp;xTimesY=false&amp;xSquared=false&amp;ySquared=false&amp;cosX=false&amp;sinX=false&amp;cosY=false&amp;sinY=false&amp;collectStats=false&amp;problem=classification&amp;initZero=false&amp;hideText=false&quot;</span><span class="p">,</span> <span class="n">width</span><span class="o">=</span><span class="mi">900</span><span class="p">,</span> <span class="n">height</span><span class="o">=</span><span class="mi">800</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_html">
<iframe
    width="900"
    height="800"
    src="https://www.cs.cityu.edu.hk/~ccha23/playground/#activation=linear&batchSize=10&dataset=gauss&regDataset=reg-plane&learningRate=0.03&regularizationRate=0&noise=0&networkShape=&seed=0.15891&showTestData=false&discretize=false&percTrainData=50&x=true&y=true&xTimesY=false&xSquared=false&ySquared=false&cosX=false&sinX=false&cosY=false&sinY=false&collectStats=false&problem=classification&initZero=false&hideText=false"
    frameborder="0"
    allowfullscreen
></iframe>
</div></div>
</div>
<p><strong>Exercise</strong> Try to tune the parameters to classify the Spiral dataset until the testing loss reaches 0.02. Include a screenshot below and give the permalink to your configuration.</p>
<p>YOUR ANSWER HERE</p>
<p>You can also <a class="reference external" href="https://github.com/tensorflow/tensorflow/pulls">fork and modify the code on GitHub</a> to add new features, e.g., to customize the datasets and store the trained neural network. However, since the visualization is limited 2D, it is difficult to extend the app for higher-dimensional dataset with multiple class values.</p>
<p>Nevertheless, it is possible to train a practical neural network without any coding, by using a service called the <a class="reference external" href="https://teachablemachine.withgoogle.com/">Teachable Machine</a>. E.g., you may follow the interactive slides below to learn to train a machine that recognizes musical notes.<br />
(Click the <code class="docutils literal notranslate"><span class="pre">play</span></code> button at the bottom of the slides to start the presentation.)</p>
<div class="cell tag_hide-input docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="o">%%html</span>
<span class="p">&lt;</span><span class="nt">iframe</span> <span class="na">src</span><span class="o">=</span><span class="s">&quot;https://www.cs.cityu.edu.hk/~ccha23/tm/slides.html&quot;</span> <span class="na">width</span><span class="o">=</span><span class="s">&quot;805&quot;</span> <span class="na">height</span><span class="o">=</span><span class="s">&quot;450&quot;</span> <span class="na">allow</span><span class="o">=</span><span class="s">&quot;microphone&quot;</span><span class="p">&gt;&lt;/</span><span class="nt">iframe</span><span class="p">&gt;</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_html"><iframe src="https://www.cs.cityu.edu.hk/~ccha23/tm/slides.html" width="805" height="450" allow="microphone"></iframe>
</div></div>
</div>
<p><strong>Exercise</strong> Use <a class="reference external" href="https://teachablemachine.withgoogle.com/">Teachable Machine</a> to train your machine. Explain what your machine does and include a link to it.</p>
<p>YOUR ANSWER HERE</p>
</div>
<div class="section" id="preliminaries">
<h2>Preliminaries<a class="headerlink" href="#preliminaries" title="Permalink to this headline">Â¶</a></h2>
<p>The neural network is trained using an iterative algorithm called the <em>stochastic gradient descent</em>, which requires some background on vector calculus and probability theory. The lecture series below explain the idea nicely with mathematical animations made using the python library <a class="reference external" href="https://github.com/3b1b/manim">mathematical animation engine (<code class="docutils literal notranslate"><span class="pre">manim</span></code>)</a>.</p>
<div class="cell tag_hide-input docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">display</span><span class="o">.</span><span class="n">IFrame</span><span class="p">(</span><span class="n">src</span><span class="o">=</span><span class="s2">&quot;https://www.youtube.com/embed/videoseries?list=PLZHQObOWTQDNU6R1_67000Dx_ZCJB-3pi&quot;</span><span class="p">,</span> <span class="n">width</span><span class="o">=</span><span class="mi">805</span><span class="p">,</span> <span class="n">height</span><span class="o">=</span><span class="mi">450</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_html">
<iframe
    width="805"
    height="450"
    src="https://www.youtube.com/embed/videoseries?list=PLZHQObOWTQDNU6R1_67000Dx_ZCJB-3pi"
    frameborder="0"
    allowfullscreen
></iframe>
</div></div>
</div>
<p>Instead of using the mean-squared error for the loss function, we will consider the <a class="reference external" href="https://en.wikipedia.org/wiki/Cross_entropy">cross-entropy</a> loss, which is more suitable for training a neural network classifier. We will have a glimpse of the information theory involved.
<span class="math notranslate nohighlight">\(\def\abs#1{\left\lvert #1 \right\rvert}
\def\Set#1{\left\{ #1 \right\}}
\def\mc#1{\mathcal{#1}}
\def\M#1{\boldsymbol{#1}}
\def\R#1{\mathsf{#1}}
\def\RM#1{\boldsymbol{\mathsf{#1}}}
\def\op#1{\operatorname{#1}}
\def\E{\op{E}}
\def\d{\mathrm{\mathstrut d}}
\)</span></p>
<p><strong>What to know about vector calculus?</strong></p>
<p>To help explain the theory, we will use some notations from vector linear algebra and probability theory.</p>
<ul class="simple">
<li><p><a class="reference external" href="https://en.wikipedia.org/wiki/Vector_(mathematics_and_physics)">Vectors</a> in lowercase boldface font:</p></li>
</ul>
<div class="math notranslate nohighlight">
\[\begin{split}\M{x}=\begin{bmatrix}x_1 \\ x_2 \\ \vdots \end{bmatrix}\end{split}\]</div>
<ul class="simple">
<li><p><a class="reference external" href="https://en.wikipedia.org/wiki/Matrix_(mathematics)">Matrices</a> in uppercase boldface font:</p></li>
</ul>
<div class="math notranslate nohighlight">
\[\begin{split}\M{W}=\begin{bmatrix}w_{11} &amp; w_{12} &amp; \cdots \\
w_{21} &amp; \ddots &amp;  \\
\vdots &amp;  &amp;  \end{bmatrix}\end{split}\]</div>
<ul class="simple">
<li><p><a class="reference external" href="https://en.wikipedia.org/wiki/Matrix_multiplication">Matrix multiplication</a>:</p></li>
</ul>
<div class="math notranslate nohighlight">
\[\begin{split}\M{W}\M{x} = \begin{bmatrix}w_{11} &amp; w_{12} &amp; \cdots \\
w_{21} &amp; \ddots &amp;  \\
\vdots &amp;  &amp;  \end{bmatrix}
\begin{bmatrix}x_1 \\ x_2 \\ \vdots \end{bmatrix}
=
\begin{bmatrix}w_{11}x_1 + w_{12}x_2 + \cdots \\ w_{21}x_1+\cdots \\ \vdots \end{bmatrix}
\end{split}\]</div>
<p><strong>What to know about Probability Theory?</strong></p>
<ul>
<li><p><a class="reference external" href="https://en.wikipedia.org/wiki/Random_variable">Random variables</a> in sanserif font:</p>
<div class="math notranslate nohighlight">
\[\begin{split}\underbrace{\R{y}}_{\text{random variable}}, \underbrace{\RM{x}=\begin{bmatrix}\R{x}_1 \\  \R{x}_2 \\  \vdots \end{bmatrix}}_{\text{random vector}}\end{split}\]</div>
</li>
<li><p><a class="reference external" href="https://en.wikipedia.org/wiki/Support_(mathematics)">Support sets</a> in calligraphic font:</p></li>
</ul>
<div class="math notranslate nohighlight">
\[\underbrace{\mc{Y}=\Set{0,1,\dots,k-1}}_{\text{finite set}}, \underbrace{\mc{X}=\mc{X}_1\times \mc{X}_2 \times \cdots}_{\text{product space}}\]</div>
<ul class="simple">
<li><p><a class="reference external" href="https://en.wikipedia.org/wiki/Joint_probability_distribution#Mixed_case">Joint distribution</a>:</p></li>
</ul>
<div class="math notranslate nohighlight">
\[p_{\RM{x}\R{y}}(\M{x},y)= \underbrace{p_{\R{y}|\RM{x}}(y|\M{x})}_{\underbrace{\Pr}_{\text{probability measure}\kern-3em}\Set{\R{y}=y|\RM{x}=\M{x}}} \cdot \underbrace{p_{\RM{x}}(\M{x})}_{(\underbrace{\partial_{x_1}}_{\text{partial derivative w.r.t. $x_1$}\kern-5em} \partial_{x_2}\cdots)\Pr\Set{\RM{x} \leq \M{x}}\kern-4em}\kern1em \text{where}\]</div>
<ul class="simple">
<li><p><span class="math notranslate nohighlight">\(p_{\R{y}|\RM{x}}(y|\M{x})\)</span> is the <em>probability mass function <a class="reference external" href="https://en.wikipedia.org/wiki/Probability_mass_function">(pmf)</a></em> of <span class="math notranslate nohighlight">\(\R{y}=y\in \mc{Y}\)</span> <a class="reference external" href="https://en.wikipedia.org/wiki/Conditional_probability_distribution">conditioned</a> on <span class="math notranslate nohighlight">\(\RM{x}=\M{x}\in \mc{X}\)</span>, and</p></li>
<li><p><span class="math notranslate nohighlight">\(p_{\RM{x}}(\M{x})\)</span> is the <em>(multivariate) probability density function <a class="reference external" href="https://en.wikipedia.org/wiki/Probability_density_function#Densities_associated_with_multiple_variables">(pdf)</a></em> of <span class="math notranslate nohighlight">\(\RM{x}=\M{x}\in \mc{X}\)</span>.</p></li>
</ul>
<ul class="simple">
<li><p>For any function <span class="math notranslate nohighlight">\(g\)</span> of <span class="math notranslate nohighlight">\((\RM{x},y)\)</span>, the expectations are:</p></li>
</ul>
<div class="amsmath math notranslate nohighlight" id="equation-83692bc6-551f-4c29-a6a3-e7b696b7e2ab">
<span class="eqno">(14)<a class="headerlink" href="#equation-83692bc6-551f-4c29-a6a3-e7b696b7e2ab" title="Permalink to this equation">Â¶</a></span>\[\begin{align}
\E[g(\RM{x},\R{y})|\RM{x}]&amp;=\sum_{y\in \mc{Y}} g(\RM{x},y)\cdot p_{\R{y}|\RM{x}}(y|\RM{x})\tag{conditional expectation}
\\
\E[g(\RM{x},\R{y})] &amp;=\int_{\mc{X}} \underbrace{\sum_{y\in \mc{Y}} g(\RM{x},y)\cdot \underbrace{p_{\RM{x},\R{y}}(\M{x},y)}_{p_{\R{y}|\RM{x}}(y|\M{x}) p_{\R{x}}(\M{x})}\kern-1.7em}_{\E[g(\RM{x},\R{y})|\RM{x}]}\kern1.4em\,\d \M{x} \tag{expectation}\\
&amp;= \E[\E[g(\RM{x},\R{y})|\RM{x}]] \tag{iterated expectation}
\end{align}\]</div>
<p>The followings are some manims created to introduce the above notions.</p>
<div class="cell tag_hide-input docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="o">%%html</span>
<span class="p">&lt;</span><span class="nt">b</span><span class="p">&gt;</span>Notation:<span class="p">&lt;/</span><span class="nt">b</span><span class="p">&gt;&lt;</span><span class="nt">br</span><span class="p">&gt;</span>
<span class="p">&lt;</span><span class="nt">video</span> <span class="na">width</span><span class="o">=</span><span class="s">&quot;805&quot;</span> <span class="na">height</span><span class="o">=</span><span class="s">&quot;450&quot;</span> <span class="na">controls</span><span class="p">&gt;</span>
      <span class="p">&lt;</span><span class="nt">source</span> <span class="na">src</span><span class="o">=</span><span class="s">&quot;https://www.cs.cityu.edu.hk/~ccha23/dl/Notation.mp4&quot;</span> <span class="na">type</span><span class="o">=</span><span class="s">&quot;video/mp4&quot;</span><span class="p">&gt;</span>
<span class="p">&lt;/</span><span class="nt">video</span><span class="p">&gt;</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_html"><b>Notation:</b><br>
<video width="805" height="450" controls>
      <source src="https://www.cs.cityu.edu.hk/~ccha23/dl/Notation.mp4" type="video/mp4">
</video>
</div></div>
</div>
<div class="cell tag_hide-input docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="o">%%html</span>
<span class="p">&lt;</span><span class="nt">b</span><span class="p">&gt;</span>Distribution:<span class="p">&lt;/</span><span class="nt">b</span><span class="p">&gt;&lt;</span><span class="nt">br</span><span class="p">&gt;</span>
<span class="p">&lt;</span><span class="nt">video</span> <span class="na">width</span><span class="o">=</span><span class="s">&quot;805&quot;</span> <span class="na">height</span><span class="o">=</span><span class="s">&quot;450&quot;</span> <span class="na">controls</span><span class="p">&gt;</span>
      <span class="p">&lt;</span><span class="nt">source</span> <span class="na">src</span><span class="o">=</span><span class="s">&quot;https://www.cs.cityu.edu.hk/~ccha23/dl/Distribution.mp4&quot;</span> <span class="na">type</span><span class="o">=</span><span class="s">&quot;video/mp4&quot;</span><span class="p">&gt;</span>
<span class="p">&lt;/</span><span class="nt">video</span><span class="p">&gt;</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_html"><b>Distribution:</b><br>
<video width="805" height="450" controls>
      <source src="https://www.cs.cityu.edu.hk/~ccha23/dl/Distribution.mp4" type="video/mp4">
</video>
</div></div>
</div>
<div class="cell tag_hide-input docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="o">%%html</span>
<span class="p">&lt;</span><span class="nt">b</span><span class="p">&gt;</span>Expectation:<span class="p">&lt;</span><span class="nt">br</span><span class="p">&gt;</span>
<span class="p">&lt;</span><span class="nt">video</span> <span class="na">width</span><span class="o">=</span><span class="s">&quot;805&quot;</span> <span class="na">height</span><span class="o">=</span><span class="s">&quot;450&quot;</span> <span class="na">controls</span><span class="p">&gt;</span>
      <span class="p">&lt;</span><span class="nt">source</span> <span class="na">src</span><span class="o">=</span><span class="s">&quot;https://www.cs.cityu.edu.hk/~ccha23/dl/Expectation.mp4&quot;</span> <span class="na">type</span><span class="o">=</span><span class="s">&quot;video/mp4&quot;</span><span class="p">&gt;</span>
<span class="p">&lt;/</span><span class="nt">video</span><span class="p">&gt;</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_html"><b>Expectation:<br>
<video width="805" height="450" controls>
      <source src="https://www.cs.cityu.edu.hk/~ccha23/dl/Expectation.mp4" type="video/mp4">
</video>
</div></div>
</div>
<p>You may also create your own animations with <code class="docutils literal notranslate"><span class="pre">manim</span></code> in the jupyter notebook using <code class="docutils literal notranslate"><span class="pre">jupyter_manim</span></code> and <code class="docutils literal notranslate"><span class="pre">manimlib</span></code> as described <a class="reference external" href="https://ccha23.github.io/CS1302ICP/Lecture5/Objects.html">here</a>.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">jupyter_manim</span>
<span class="kn">from</span> <span class="nn">manimlib.imports</span> <span class="kn">import</span> <span class="o">*</span>
</pre></div>
</div>
</div>
</div>
<p><strong>Exercise</strong> Run the following cell and see the effect when changing</p>
<ul class="simple">
<li><p>Mobjects: <code class="docutils literal notranslate"><span class="pre">TextMobject('Hello,</span> <span class="pre">World!')</span></code> to <code class="docutils literal notranslate"><span class="pre">TexMobject(r'E=mc^2')</span></code> or <code class="docutils literal notranslate"><span class="pre">Circle()</span></code> or <code class="docutils literal notranslate"><span class="pre">Square()</span></code>.</p></li>
<li><p>Animation objects: <code class="docutils literal notranslate"><span class="pre">Write</span></code> to <code class="docutils literal notranslate"><span class="pre">FadeIn</span></code> or <code class="docutils literal notranslate"><span class="pre">GrowFromCenter</span></code>.</p></li>
</ul>
<p>You may take a look at the documentation <a class="reference external" href="https://docs.manim.community/en/v0.2.0/index.html">here</a> and a more detailed <a class="reference external" href="https://talkingphysics.wordpress.com/2019/01/08/getting-started-animating-with-manim-and-python-3-7/">tutorial</a> here.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="o">%%</span><span class="k">manim</span> HelloWorld -l
class HelloWorld(Scene):
    def construct(self):
        self.play(Write(TextMobject(&#39;Hello, World!&#39;)))
</pre></div>
</div>
</div>
</div>
</div>
<div class="section" id="classification-problem">
<h2>Classification Problem<a class="headerlink" href="#classification-problem" title="Permalink to this headline">Â¶</a></h2>
<p>A neural network learns from many examples collected together as a <em>dataset</em>. For instance, the <a class="reference external" href="https://en.wikipedia.org/wiki/MNIST_database">MNIST (Modified National Institute of Standards and Technology)</a> dataset consists of labeled handwritten digits.</p>
<p><a title="Josef Steppan, CC BY-SA 4.0 &lt;https://creativecommons.org/licenses/by-sa/4.0&gt;, via Wikimedia Commons" href="https://commons.wikimedia.org/wiki/File:MnistExamples.png"><img alt="MnistExamples" src="https://upload.wikimedia.org/wikipedia/commons/2/27/MnistExamples.png"></a></p>
<p><strong>What is an example in a dataset?</strong></p>
<p>A dataset is a sequence</p>
<div class="amsmath math notranslate nohighlight" id="equation-8288e1db-7068-4fac-8596-6fa229a0862c">
<span class="eqno">(15)<a class="headerlink" href="#equation-8288e1db-7068-4fac-8596-6fa229a0862c" title="Permalink to this equation">Â¶</a></span>\[\begin{align}
(\RM{x}_1,\R{y}_1),(\RM{x}_2,\R{y}_2), \dots\tag{dataset}
\end{align}\]</div>
<p>of <em>tuples/instances</em> <span class="math notranslate nohighlight">\((\RM{x}_i,\R{y}_i)\)</span>, each of which consists of</p>
<ul class="simple">
<li><p>an <em>input feature vector</em> <span class="math notranslate nohighlight">\(\RM{x}_i\)</span> such as an image of a handwritten digit and</p></li>
<li><p>a <em>label</em> <span class="math notranslate nohighlight">\(\R{y}_i\)</span> such as the digit type of the handwritten digit.</p></li>
</ul>
<p><strong>What to learn from the dataset?</strong></p>
<p>One of the problem in Machine Learning is <em>classification</em>: The goal is to train a <em>classifier</em> that predicts a label <span class="math notranslate nohighlight">\(\R{y}\)</span> for an input feature <span class="math notranslate nohighlight">\(\RM{x}\)</span>:</p>
<ul class="simple">
<li><p>A hard-decision classifier is a function <span class="math notranslate nohighlight">\(f:\mc{X}\to \mc{Y}\)</span> such that
<span class="math notranslate nohighlight">\(f(\RM{x})\)</span> predicts <span class="math notranslate nohighlight">\(\R{y}\)</span>.</p></li>
<li><p>A probabilistic classifier is a conditional distribution <span class="math notranslate nohighlight">\(q_{\R{y}|\RM{x}}\)</span> that estimates <span class="math notranslate nohighlight">\(p_{\R{y}|\RM{x}}\)</span>.</p></li>
</ul>
<p>For MNIST, the goal is to classify the digit type of a handwritten digit.  When given a handwritten digit,</p>
<ul class="simple">
<li><p>a hard-decision classifier returns a digit type, and</p></li>
<li><p>a probabilistic classifier returns a distribution of the digit types.</p></li>
</ul>
<p><strong>Why consider a probabilistic classifier?</strong></p>
<p>We often train a neural network as a probabilistic classifer because:</p>
<ul>
<li><p>A probabilistic classifer is more general and can give a hard decision as well</p>
<div class="math notranslate nohighlight">
\[f(\RM{x}):=\arg\max_{y\in \mc{Y}} q_{\R{y}|\RM{x}}(y|\RM{x})\]</div>
<p>by returning the estimated most likely digit type.</p>
</li>
<li><p>A neural network can model the distribution <span class="math notranslate nohighlight">\(p_{\R{y}|\RM{x}}(\cdot|\RM{x})\)</span> better than <span class="math notranslate nohighlight">\(\R{y}\)</span> because its output is continous.</p></li>
</ul>
<p><strong>Why can we learn from examples?</strong></p>
<p>For the problem to be meaningful, <span class="math notranslate nohighlight">\((\RM{x},\R{y})\)</span> is assumed to be random with some unknown joint distribution <span class="math notranslate nohighlight">\(p_{\RM{x},\R{y}}\)</span>.</p>
<ul class="simple">
<li><p>If we always had <span class="math notranslate nohighlight">\(\R{y}=y\)</span> instead, then a perfect classifier can just return <span class="math notranslate nohighlight">\(y\)</span> without even looking at <span class="math notranslate nohighlight">\(\RM{x}\)</span>.</p></li>
<li><p>If <span class="math notranslate nohighlight">\(p_{\RM{x},\R{y}}\)</span> were known instead, then <span class="math notranslate nohighlight">\(p_{\R{y}|\RM{x}}\)</span> would also be known and therefore needed not be estimated.</p></li>
</ul>
<p>Examples are often collected randomly and independently from a population, i.e., as <a class="reference external" href="https://en.wikipedia.org/wiki/Independent_and_identically_distributed_random_variables">i.i.d. samples</a> of <span class="math notranslate nohighlight">\((\RM{x},\R{y})\)</span>:</p>
<div class="math notranslate nohighlight">
\[(\RM{x}_1,\R{y}_1), (\RM{x}_2,\R{y}_2), \dots\sim_{\text{i.i.d.}} p_{\RM{x},\R{y}}.\]</div>
<ul class="simple">
<li><p>If all the examples were the same instead, the examples could not show the pattern of how <span class="math notranslate nohighlight">\(\R{y}\)</span> depended on <span class="math notranslate nohighlight">\(\RM{x}\)</span>.</p></li>
<li><p>The observed distribution of i.i.d. samples converge to the unknown distribution by the <a class="reference external" href="https://en.wikipedia.org/wiki/Law_of_large_numbers">law of large number</a>.</p></li>
</ul>
<p><strong>How to determine if a classifier is good?</strong></p>
<p>Ultimately, we desire a classifier with the maximum accuracy in predicting <span class="math notranslate nohighlight">\(\R{y}\)</span> but doing so is <a class="reference external" href="https://en.wikipedia.org/wiki/Loss_functions_for_classification">computationally too difficult</a>.</p>
<p>Instead, we regard a classification algorithm to be reasonably good if it can achieve the maximum possible accuracy as the number of training samples goes to <span class="math notranslate nohighlight">\(\infty\)</span>. This is more formally stated below:</p>
<p><strong>Definition</strong> A probabilistic classifier for the input feature <span class="math notranslate nohighlight">\(\RM{x}\)</span> and label <span class="math notranslate nohighlight">\(\R{y}\)</span> with unknown joint distribution  is a conditional pmf</p>
<div class="math notranslate nohighlight">
\[
\R{q}_{\R{y}|\RM{x}}(y|\RM{x})\qquad \text{for }\M{x}\in \mc{X}, y\in \mc{Y}
\]</div>
<p>defined as a function of the i.i.d. samples</p>
<div class="math notranslate nohighlight">
\[\{(\RM{x}_i,\R{y}_i)\}_{i=1}^N\]</div>
<p>of <span class="math notranslate nohighlight">\((\RM{x},\R{y})\)</span> (but independent of <span class="math notranslate nohighlight">\((\RM{x},\R{y})\)</span>).
The classifier is said to be a <em>consistent</em> estimate (of <span class="math notranslate nohighlight">\(p_{\R{y}|\M{x}}\)</span>) if</p>
<div class="amsmath math notranslate nohighlight" id="equation-ec0709a0-4ce3-4569-8faf-4037f6c97172">
<span class="eqno">(16)<a class="headerlink" href="#equation-ec0709a0-4ce3-4569-8faf-4037f6c97172" title="Permalink to this equation">Â¶</a></span>\[\begin{align}
\lim_{N\to \infty} \Pr\Set{\R{q}_{\R{y}|\RM{x}}(y|\RM{x})=p_{\R{y}|\RM{x}}(y|\RM{x})\text{ for all } y\in \mc{Y}}=1,\tag{consistency}
\end{align}\]</div>
<p>namely, <span class="math notranslate nohighlight">\(\R{q}_{\R{y}|\RM{x}}(y|\RM{x})\)</span> converges almost surely (a.s.) to <span class="math notranslate nohighlight">\(p_{\R{y}|\RM{x}}\)</span>. <span class="math notranslate nohighlight">\(\square\)</span></p>
<p>A consistent probabilistic classifier gives rise to an asymptotically optimal hard-decision classifier that achieves the maximum accuracy.</p>
<p><strong>Proposition</strong> If for some <span class="math notranslate nohighlight">\(\epsilon\geq 0\)</span> that</p>
<div class="math notranslate nohighlight">
\[\Pr\Set{\R{q}_{\R{y}|\RM{x}}(y|\RM{x})=p_{\R{y}|\RM{x}}(y|\RM{x}) \text{ for all } y\in \mc{Y}}=1-\epsilon,\]</div>
<p>the (hard-decision) classifier</p>
<div class="amsmath math notranslate nohighlight" id="equation-6446a426-ec1c-4364-a9f0-c8327c3adc24">
<span class="eqno">(17)<a class="headerlink" href="#equation-6446a426-ec1c-4364-a9f0-c8327c3adc24" title="Permalink to this equation">Â¶</a></span>\[\begin{align}\R{f}(\RM{x}):=\arg\max_{y\in \mc{Y}} \R{q}_{\R{y}|\RM{x}}(y|\RM{x})\tag{hard decision}\end{align}\]</div>
<p>achieves an accuracy</p>
<div class="amsmath math notranslate nohighlight" id="equation-21091420-8ea2-45d8-ad94-948c26e54e02">
<span class="eqno">(18)<a class="headerlink" href="#equation-21091420-8ea2-45d8-ad94-948c26e54e02" title="Permalink to this equation">Â¶</a></span>\[\begin{align}
\sup_{f:\mc{X}\to \mc{Y}} \Pr(\R{y}= f(\RM{x})) &amp;\geq \E\left[\max_{y\in \mc{Y}} p_{\R{y}|\M{x}}(y|\RM{x})\right] - \epsilon.\tag{accuracy lower bound}
\end{align}\]</div>
<p>where the expectation is the maximum possible accuracy. <span class="math notranslate nohighlight">\(\square\)</span></p>
<p><em>Proof:</em> For any classifier <span class="math notranslate nohighlight">\(f\)</span>,</p>
<div class="math notranslate nohighlight">
\[\begin{split} \begin{align*}
\Pr(\R{y}= f(\RM{x}))
&amp;= \E[p_{\R{y}|\M{x}}(f(\RM{x})|\RM{x})] \\
&amp;\leq \E\left[\max_{y\in \mc{Y}} p_{\R{y}|\M{x}}(y|\RM{x})\right]\end{align*}
\end{split}\]</div>
<p>where the last inequality is achievable with equality with the hard-decision classifier and <span class="math notranslate nohighlight">\(\R{q}\)</span> replaced by <span class="math notranslate nohighlight">\(p\)</span>. This implies the desired accuracy lower bound for the case <span class="math notranslate nohighlight">\(\epsilon=0\)</span>. The more general case with <span class="math notranslate nohighlight">\(\epsilon\geq 0\)</span> can be derived similarly. <span class="math notranslate nohighlight">\(\blacksquare\)</span></p>
<p><strong>How can we obtain a consistent classifier?</strong></p>
<p>We train a neural network to minimize certain <em>loss</em>. A common loss function for classification uses the <a class="reference external" href="https://en.wikipedia.org/wiki/Cross_entropy">cross entropy</a> measure in information theory.</p>
<p>The theoretical underpinning is the following identity that relates three information quantities:</p>
<div class="amsmath math notranslate nohighlight" id="equation-1e50add1-ce49-4ac2-a480-282d95027636">
<span class="eqno">(19)<a class="headerlink" href="#equation-1e50add1-ce49-4ac2-a480-282d95027636" title="Permalink to this equation">Â¶</a></span>\[\begin{align}
\overbrace{\E\left[\log \frac{1}{q_{\R{y}|\RM{x}}(\R{y}|\RM{x})}\right]}^{ \text{Cross entropy}\\ H(p_{\R{y}|\RM{x}}\|q_{\R{y}|\RM{x}}|p_{\RM{x}}):=} &amp;\equiv \overbrace{\E\left[\log \frac{1}{p_{\R{y}|\RM{x}}(\R{y}|\RM{x})}\right]}^{\text{Conditional entropy}\\ H(\R{y}|\RM{x}):=} + \overbrace{\E\left[\log \frac{p_{\R{y}|\RM{x}}(\R{y}|\RM{x})}{q_{\R{y}|\RM{x}}(\R{y}|\RM{x})}\right].}^{\text{Divergence}\\ D(p_{\R{y}|\RM{x}}\|q_{\R{y}|\RM{x}}|p_{\RM{x}}):=}\tag{identity}
\end{align}\]</div>
<p>The identity can be proved quite easily using the linearity of expectation</p>
<div class="math notranslate nohighlight">
\[ \E[\R{u}+\R{v}]=\E[\R{u}]+\E[\R{v}],\]</div>
<p>and a property of logarithm that</p>
<div class="math notranslate nohighlight">
\[\log uv = \log u+ \log v.\]</div>
<div class="cell tag_hide-input docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="o">%%html</span>
<span class="p">&lt;</span><span class="nt">b</span><span class="p">&gt;</span>Information Identity<span class="p">&lt;/</span><span class="nt">b</span><span class="p">&gt;&lt;</span><span class="nt">br</span><span class="p">&gt;</span>
<span class="p">&lt;</span><span class="nt">video</span> <span class="na">width</span><span class="o">=</span><span class="s">&quot;805&quot;</span> <span class="na">height</span><span class="o">=</span><span class="s">&quot;450&quot;</span> <span class="na">controls</span><span class="p">&gt;</span>
      <span class="p">&lt;</span><span class="nt">source</span> <span class="na">src</span><span class="o">=</span><span class="s">&quot;https://www.cs.cityu.edu.hk/~ccha23/dl/InformationIdentity.mp4&quot;</span> <span class="na">type</span><span class="o">=</span><span class="s">&quot;video/mp4&quot;</span><span class="p">&gt;</span>
<span class="p">&lt;/</span><span class="nt">video</span><span class="p">&gt;</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_html"><b>Information Identity</b><br>
<video width="805" height="450" controls>
      <source src="https://www.cs.cityu.edu.hk/~ccha23/dl/InformationIdentity.mp4" type="video/mp4">
</video>
</div></div>
</div>
<p><strong>Proposition</strong> With <span class="math notranslate nohighlight">\(q_{\R{y}|\RM{x}}(y|\M{x})\)</span> being a valid pmf of a random variable taking values from <span class="math notranslate nohighlight">\(\mc{Y}\)</span> conditioned on a random variable taking values from <span class="math notranslate nohighlight">\(\mc{X}\)</span>,</p>
<div class="amsmath math notranslate nohighlight" id="equation-6c8fa09a-8490-465b-a20d-b89aef12fd45">
<span class="eqno">(20)<a class="headerlink" href="#equation-6c8fa09a-8490-465b-a20d-b89aef12fd45" title="Permalink to this equation">Â¶</a></span>\[\begin{align}
\min_{q_{\R{y}|\RM{x}}} H(p_{\R{y}|\RM{x}}\|q_{\R{y}|\RM{x}}|p_{\RM{x}})
&amp;= H(\R{y}|\RM{x})
\end{align}\]</div>
<p>and the optimal solution equals <span class="math notranslate nohighlight">\(p_{\R{y}|\RM{x}}(y|\RM{x})\)</span> a.s. for all <span class="math notranslate nohighlight">\(y\in \mc{Y}\)</span>. <span class="math notranslate nohighlight">\(\square\)</span></p>
<p>Hence, a neural network that minimizes the cross entropy equals <span class="math notranslate nohighlight">\(p_{\R{y}|\RM{x}}(y|\RM{x})\)</span> a.s. for all <span class="math notranslate nohighlight">\(y\in \mc{Y}\)</span> and any possible input image <span class="math notranslate nohighlight">\(\RM{x}\)</span>.</p>
<p><em>Proof:</em> It suffices to show that</p>
<div class="amsmath math notranslate nohighlight" id="equation-11097135-dbbf-4d66-a6c0-f9d964791436">
<span class="eqno">(21)<a class="headerlink" href="#equation-11097135-dbbf-4d66-a6c0-f9d964791436" title="Permalink to this equation">Â¶</a></span>\[\begin{align}
D(p_{\R{y}|\RM{x}}\|q_{\R{y}|\RM{x}}|p_{\RM{x}})\geq 0 \tag{positivity of divergence}
\end{align}\]</div>
<p>with equality iff <span class="math notranslate nohighlight">\(q_{\R{y}|\RM{x}}(y|\RM{x})=p_{\R{y}|\RM{x}}(y|\RM{x})\)</span> a.s. This, in turn, can be proved using the <a class="reference external" href="https://en.wikipedia.org/wiki/Log_sum_inequality">log-sum inequality</a>:</p>
<div class="amsmath math notranslate nohighlight" id="equation-72e78b00-100e-4ec1-aa34-9ada57703506">
<span class="eqno">(22)<a class="headerlink" href="#equation-72e78b00-100e-4ec1-aa34-9ada57703506" title="Permalink to this equation">Â¶</a></span>\[\begin{align}
\sum_{i} a_i \log\left(\frac{a_i}{b_i}\right) \geq (\textstyle \sum_{i} a_i) \log\left(\frac{\sum_{i} a_i}{\sum_{i} b_i}\right)\tag{log-sum inequality}
\end{align}\]</div>
<p>for any sequences <span class="math notranslate nohighlight">\(\{a_i\}\)</span>, <span class="math notranslate nohighlight">\(\{b_i\}\)</span>, and <span class="math notranslate nohighlight">\(\{c_i\}\)</span>. <span class="math notranslate nohighlight">\(\blacksquare\)</span></p>
</div>
<div class="section" id="data-preparation">
<h2>Data Preparation<a class="headerlink" href="#data-preparation" title="Permalink to this headline">Â¶</a></h2>
<div class="section" id="load-the-dataset">
<h3>Load the dataset<a class="headerlink" href="#load-the-dataset" title="Permalink to this headline">Â¶</a></h3>
<p>Like the iris dataset, the MNIST dataset can be obtained in many ways due to its popularity in image recognition. For instance, one may use <code class="docutils literal notranslate"><span class="pre">tensorflow.keras.datasets.mnist.load_data</span></code> to load the data as tuples/arrays and convert it to <code class="docutils literal notranslate"><span class="pre">DataFrame</span></code>. However, training a neural network often requires a lot of data and computational power. It may be inefficient or impossible to load all data into memory.</p>
<p>A better way is to use the package <a class="reference external" href="https://blog.tensorflow.org/2019/02/introducing-tensorflow-datasets.html"><code class="docutils literal notranslate"><span class="pre">tensorflow_datasets</span></code></a>, which lazily load the dataset and prepare the data as <a class="reference external" href="https://www.tensorflow.org/guide/tensor"><code class="docutils literal notranslate"><span class="pre">Tensor</span></code>s</a>, which can be operated faster by GPU or TPU instead of CPU.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">tensorflow_datasets</span> <span class="k">as</span> <span class="nn">tfds</span>  <span class="c1"># give a shorter name tfds for convenience</span>
<span class="kn">import</span> <span class="nn">os</span>

<span class="n">user_home</span> <span class="o">=</span> <span class="n">os</span><span class="o">.</span><span class="n">getenv</span><span class="p">(</span><span class="s2">&quot;HOME&quot;</span><span class="p">)</span>  <span class="c1"># get user home directory</span>
<span class="n">data_dir</span> <span class="o">=</span> <span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="n">user_home</span><span class="p">,</span> <span class="s2">&quot;data&quot;</span><span class="p">)</span>  <span class="c1"># download folder for data</span>

<span class="n">ds</span><span class="p">,</span> <span class="n">ds_info</span> <span class="o">=</span> <span class="n">tfds</span><span class="o">.</span><span class="n">load</span><span class="p">(</span>
    <span class="s1">&#39;mnist&#39;</span><span class="p">,</span>
    <span class="n">data_dir</span><span class="o">=</span><span class="n">data_dir</span><span class="p">,</span>  <span class="c1"># download location</span>
    <span class="n">as_supervised</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>  <span class="c1"># separate input features and label</span>
    <span class="n">with_info</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>  <span class="c1"># return information of the dataset</span>
<span class="p">)</span>

<span class="c1"># print information related to loading the dataset</span>
<span class="kn">import</span> <span class="nn">pprint</span> <span class="k">as</span> <span class="nn">pp</span>
<span class="nb">print</span><span class="p">(</span><span class="s1">&#39;-&#39;</span> <span class="o">*</span> <span class="mi">79</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s1">&#39;Data downloaded to </span><span class="si">{</span><span class="n">data_dir</span><span class="si">}</span><span class="s1">&#39;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s1">&#39;Data to be loaded in memory:&#39;</span><span class="p">)</span>
<span class="n">pp</span><span class="o">.</span><span class="n">pprint</span><span class="p">(</span><span class="n">ds</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<p>The function <code class="docutils literal notranslate"><span class="pre">tfds.load</span></code> download the data to <code class="docutils literal notranslate"><span class="pre">data_dir</span></code> and prepare it for loading using variable <code class="docutils literal notranslate"><span class="pre">ds</span></code>. In particular, the dataset is split into</p>
<ul class="simple">
<li><p>a training set <code class="docutils literal notranslate"><span class="pre">ds[&quot;train&quot;]</span></code> and</p></li>
<li><p>a test set <code class="docutils literal notranslate"><span class="pre">ds[&quot;test&quot;]</span></code>.</p></li>
</ul>
<p><code class="docutils literal notranslate"><span class="pre">tfds.load?</span></code> shows more information about the function. E.g., we can control the split ratio using the argument <a class="reference external" href="https://www.tensorflow.org/datasets/splits"><code class="docutils literal notranslate"><span class="pre">split</span></code></a>.</p>
<p><strong>Why split the data?</strong></p>
<p>The test set is used to evaluate the performance of a neural network trained using the training set (separate from the test set).</p>
<p>The purpose of separating the test set from the training set is to avoid <em>overly-optimistic</em> performance estimate. Why?</p>
<p>Suppose the final exam questions (test set) are the same as the previous homework questions (training set).</p>
<ul class="simple">
<li><p>Students may get a high exam score simply by studying the model answers to the homework instead of understanding entire subject.</p></li>
<li><p>The exam score is therefore an overly-optimistic estimate of the studentsâ€™ understanding of the subject.</p></li>
</ul>
<p><strong>Exercise</strong> Assign to <code class="docutils literal notranslate"><span class="pre">train_size</span></code> and <code class="docutils literal notranslate"><span class="pre">test_size</span></code> the numbers of instances in the training set and test set respectively.</p>
<p><em>Hint: Both the training and test sets are loaded as <a class="reference external" href="https://www.tensorflow.org/api_docs/python/tf/data/Dataset"><code class="docutils literal notranslate"><span class="pre">Dataset</span></code> objects</a>. Since the loading is lazy, i.e., the data is not yet in memory, we cannot count the number of instances directly. Instead, we obtain such information from <code class="docutils literal notranslate"><span class="pre">ds_info</span></code>.</em></p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># YOUR CODE HERE</span>
<span class="k">raise</span> <span class="ne">NotImplementedError</span><span class="p">()</span>
<span class="n">train_size</span><span class="p">,</span> <span class="n">test_size</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># tests</span>
</pre></div>
</div>
</div>
</div>
<p>Note that the training set is often much larger than the test set especially for deep learning because</p>
<ul class="simple">
<li><p>training a neural network requires many examples but</p></li>
<li><p>estimating its performance does not.</p></li>
</ul>
</div>
<div class="section" id="show-an-example">
<h3>Show an example<a class="headerlink" href="#show-an-example" title="Permalink to this headline">Â¶</a></h3>
<p>The following retrieves an example from the training set.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="k">for</span> <span class="n">image</span><span class="p">,</span> <span class="n">label</span> <span class="ow">in</span> <span class="n">ds</span><span class="p">[</span><span class="s2">&quot;train&quot;</span><span class="p">]</span><span class="o">.</span><span class="n">take</span><span class="p">(</span><span class="mi">1</span><span class="p">):</span>
    <span class="nb">print</span><span class="p">(</span>
        <span class="sa">f</span><span class="s1">&#39;image dtype: </span><span class="si">{</span><span class="nb">type</span><span class="p">(</span><span class="n">image</span><span class="p">)</span><span class="si">}</span><span class="s1"> shape: </span><span class="si">{</span><span class="n">image</span><span class="o">.</span><span class="n">shape</span><span class="si">}</span><span class="s1"> element dtype: </span><span class="si">{</span><span class="n">image</span><span class="o">.</span><span class="n">dtype</span><span class="si">}</span><span class="s1">&#39;</span>
    <span class="p">)</span>
    <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s1">&#39;label dtype: </span><span class="si">{</span><span class="n">label</span><span class="o">.</span><span class="n">dtype</span><span class="si">}</span><span class="s1">&#39;</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<p>The for loop above takes one example from <code class="docutils literal notranslate"><span class="pre">ds[&quot;train&quot;]</span></code> using the method <a class="reference external" href="https://www.tensorflow.org/api_docs/python/tf/data/Dataset#take"><code class="docutils literal notranslate"><span class="pre">take</span></code></a> and print its data types.</p>
<ul class="simple">
<li><p>The handwritten digit is represented by a 28x28x1 <a class="reference external" href="https://www.tensorflow.org/guide/eager"><code class="docutils literal notranslate"><span class="pre">EagerTensor</span></code></a>, which is essentially a 2D array of bytes (8-bit unsigned integers <code class="docutils literal notranslate"><span class="pre">uint8</span></code>).</p></li>
<li><p>The digit type is an integer.</p></li>
</ul>
<p>The following function plots the image using the <code class="docutils literal notranslate"><span class="pre">imshow</span></code> function from <code class="docutils literal notranslate"><span class="pre">matplotlib.pyplot</span></code>. We set the parameter <code class="docutils literal notranslate"><span class="pre">cmap</span></code> to <code class="docutils literal notranslate"><span class="pre">gray_r</span></code> so the color is darker if the pixel value is larger. The slice operator <code class="docutils literal notranslate"><span class="pre">[:,:,0]</span></code> for the image reshaped the numpy array from 3 dimensions to 2 dimensions.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="k">def</span> <span class="nf">plot_mnist_image</span><span class="p">(</span><span class="n">example</span><span class="p">,</span> <span class="n">ax</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">pixel_format</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
    <span class="p">(</span><span class="n">image</span><span class="p">,</span> <span class="n">label</span><span class="p">)</span> <span class="o">=</span> <span class="n">example</span>
    <span class="k">if</span> <span class="n">ax</span> <span class="o">==</span> <span class="kc">None</span><span class="p">:</span>
        <span class="n">ax</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">gca</span><span class="p">()</span>
    <span class="n">ax</span><span class="o">.</span><span class="n">title</span><span class="o">.</span><span class="n">set_text</span><span class="p">(</span><span class="n">label</span><span class="o">.</span><span class="n">numpy</span><span class="p">())</span>  <span class="c1"># show digit type as plot title</span>
    <span class="n">ax</span><span class="o">.</span><span class="n">imshow</span><span class="p">(</span><span class="n">image</span><span class="p">[:,</span> <span class="p">:,</span> <span class="mi">0</span><span class="p">],</span> <span class="n">cmap</span><span class="o">=</span><span class="s2">&quot;gray_r&quot;</span><span class="p">)</span>  <span class="c1"># show image</span>
    <span class="c1"># Major ticks</span>
    <span class="n">ax</span><span class="o">.</span><span class="n">set_xticks</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">arange</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="mi">28</span><span class="p">,</span> <span class="mi">3</span><span class="p">))</span>
    <span class="n">ax</span><span class="o">.</span><span class="n">set_yticks</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">arange</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="mi">28</span><span class="p">,</span> <span class="mi">3</span><span class="p">))</span>
    <span class="c1"># Minor ticks</span>
    <span class="n">ax</span><span class="o">.</span><span class="n">set_xticks</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">arange</span><span class="p">(</span><span class="o">-.</span><span class="mi">5</span><span class="p">,</span> <span class="mi">28</span><span class="p">,</span> <span class="mi">1</span><span class="p">),</span> <span class="n">minor</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
    <span class="n">ax</span><span class="o">.</span><span class="n">set_yticks</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">arange</span><span class="p">(</span><span class="o">-.</span><span class="mi">5</span><span class="p">,</span> <span class="mi">28</span><span class="p">,</span> <span class="mi">1</span><span class="p">),</span> <span class="n">minor</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
    <span class="k">if</span> <span class="n">pixel_format</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
        <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">28</span><span class="p">):</span>
            <span class="k">for</span> <span class="n">j</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">28</span><span class="p">):</span>
                <span class="n">ax</span><span class="o">.</span><span class="n">text</span><span class="p">(</span>
                    <span class="n">j</span><span class="p">,</span>
                    <span class="n">i</span><span class="p">,</span>
                    <span class="n">pixel_format</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">image</span><span class="p">[</span><span class="n">i</span><span class="p">,</span> <span class="n">j</span><span class="p">,</span>
                                              <span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">numpy</span><span class="p">()),</span>  <span class="c1"># show pixel value</span>
                    <span class="n">va</span><span class="o">=</span><span class="s1">&#39;center&#39;</span><span class="p">,</span>
                    <span class="n">ha</span><span class="o">=</span><span class="s1">&#39;center&#39;</span><span class="p">,</span>
                    <span class="n">color</span><span class="o">=</span><span class="s1">&#39;white&#39;</span><span class="p">,</span>
                    <span class="n">fontweight</span><span class="o">=</span><span class="s1">&#39;bold&#39;</span><span class="p">,</span>
                    <span class="n">fontsize</span><span class="o">=</span><span class="s1">&#39;small&#39;</span><span class="p">)</span>
        <span class="n">ax</span><span class="o">.</span><span class="n">grid</span><span class="p">(</span><span class="n">color</span><span class="o">=</span><span class="s1">&#39;lightblue&#39;</span><span class="p">,</span> <span class="n">linestyle</span><span class="o">=</span><span class="s1">&#39;-&#39;</span><span class="p">,</span> <span class="n">linewidth</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">which</span><span class="o">=</span><span class="s1">&#39;minor&#39;</span><span class="p">)</span>
        <span class="n">ax</span><span class="o">.</span><span class="n">set_xlabel</span><span class="p">(</span><span class="s1">&#39;2nd dimension&#39;</span><span class="p">)</span>
        <span class="n">ax</span><span class="o">.</span><span class="n">set_ylabel</span><span class="p">(</span><span class="s1">&#39;1st dimension&#39;</span><span class="p">)</span>
        <span class="n">ax</span><span class="o">.</span><span class="n">title</span><span class="o">.</span><span class="n">set_text</span><span class="p">(</span><span class="s1">&#39;Image with label &#39;</span> <span class="o">+</span> <span class="n">ax</span><span class="o">.</span><span class="n">title</span><span class="o">.</span><span class="n">get_text</span><span class="p">())</span>


<span class="k">if</span> <span class="nb">input</span><span class="p">(</span><span class="s1">&#39;Execute? [Y/n]&#39;</span><span class="p">)</span><span class="o">.</span><span class="n">lower</span> <span class="o">!=</span> <span class="s1">&#39;n&#39;</span><span class="p">:</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">figure</span><span class="p">(</span><span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">11</span><span class="p">,</span> <span class="mi">11</span><span class="p">),</span> <span class="n">dpi</span><span class="o">=</span><span class="mi">80</span><span class="p">)</span>
    <span class="k">for</span> <span class="n">example</span> <span class="ow">in</span> <span class="n">ds</span><span class="p">[</span><span class="s2">&quot;train&quot;</span><span class="p">]</span><span class="o">.</span><span class="n">take</span><span class="p">(</span><span class="mi">1</span><span class="p">):</span>
        <span class="n">plot_mnist_image</span><span class="p">(</span><span class="n">example</span><span class="p">,</span> <span class="n">pixel_format</span><span class="o">=</span><span class="s1">&#39;</span><span class="si">{}</span><span class="s1">&#39;</span><span class="p">)</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
</pre></div>
</div>
</div>
</div>
<p><strong>Exercise</strong> Complete the following code to generate a matrix plot of the first 50 examples from the training sets.<br />
The parameter <code class="docutils literal notranslate"><span class="pre">nrows</span></code> and <code class="docutils literal notranslate"><span class="pre">ncols</span></code> specify the number of rows and columns respectively. You code may look like</p>
<div class="highlight-Python notranslate"><div class="highlight"><pre><span></span><span class="o">...</span>
        <span class="k">for</span> <span class="n">ax</span><span class="p">,</span> <span class="n">example</span> <span class="ow">in</span> <span class="nb">zip</span><span class="p">(</span><span class="n">axes</span><span class="o">.</span><span class="n">flat</span><span class="p">,</span> <span class="n">ds</span><span class="p">[</span><span class="s2">&quot;train&quot;</span><span class="p">]</span><span class="o">.</span><span class="n">____</span><span class="p">(</span><span class="n">nrows</span> <span class="o">*</span> <span class="n">ncols</span><span class="p">)):</span>
            <span class="n">plot_mnist_image</span><span class="p">(</span><span class="n">_______</span><span class="p">,</span> <span class="n">ax</span><span class="p">)</span>
            <span class="n">ax</span><span class="o">.</span><span class="n">axes</span><span class="o">.</span><span class="n">xaxis</span><span class="o">.</span><span class="n">set_visible</span><span class="p">(</span><span class="kc">False</span><span class="p">)</span>
            <span class="n">ax</span><span class="o">.</span><span class="n">axes</span><span class="o">.</span><span class="n">yaxis</span><span class="o">.</span><span class="n">set_visible</span><span class="p">(</span><span class="kc">False</span><span class="p">)</span>
<span class="o">...</span>
</pre></div>
</div>
<p>and the output image should look like
<img alt="mnist_examples" src="../_images/mnist_examples.svg" /></p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="k">if</span> <span class="nb">input</span><span class="p">(</span><span class="s1">&#39;Execute? [Y/n]&#39;</span><span class="p">)</span><span class="o">.</span><span class="n">lower</span> <span class="o">!=</span> <span class="s1">&#39;n&#39;</span><span class="p">:</span>
    <span class="k">def</span> <span class="nf">plot_mnist_image_matrix</span><span class="p">(</span><span class="n">ds</span><span class="p">,</span> <span class="n">nrows</span><span class="o">=</span><span class="mi">5</span><span class="p">,</span> <span class="n">ncols</span><span class="o">=</span><span class="mi">10</span><span class="p">):</span>
        <span class="n">fig</span><span class="p">,</span> <span class="n">axes</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">subplots</span><span class="p">(</span><span class="n">nrows</span><span class="o">=</span><span class="n">nrows</span><span class="p">,</span> <span class="n">ncols</span><span class="o">=</span><span class="n">ncols</span><span class="p">)</span>

        <span class="c1"># YOUR CODE HERE</span>
        <span class="k">raise</span> <span class="ne">NotImplementedError</span><span class="p">()</span>

        <span class="n">fig</span><span class="o">.</span><span class="n">tight_layout</span><span class="p">()</span>  <span class="c1"># adjust spacing between subplots automatically</span>
        <span class="k">return</span> <span class="n">fig</span><span class="p">,</span> <span class="n">axes</span>


    <span class="n">fig</span><span class="p">,</span> <span class="n">axes</span> <span class="o">=</span> <span class="n">plot_mnist_image_matrix</span><span class="p">(</span><span class="n">ds</span><span class="p">,</span> <span class="n">nrows</span><span class="o">=</span><span class="mi">5</span><span class="p">)</span>
    <span class="n">fig</span><span class="o">.</span><span class="n">set_figwidth</span><span class="p">(</span><span class="mi">9</span><span class="p">)</span>
    <span class="n">fig</span><span class="o">.</span><span class="n">set_figheight</span><span class="p">(</span><span class="mi">6</span><span class="p">)</span>
    <span class="n">fig</span><span class="o">.</span><span class="n">set_dpi</span><span class="p">(</span><span class="mi">80</span><span class="p">)</span>
    <span class="c1"># plt.savefig(&#39;mnist_examples.svg&#39;)</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
</pre></div>
</div>
</div>
</div>
</div>
<div class="section" id="preprocess-the-data">
<h3>Preprocess the data<a class="headerlink" href="#preprocess-the-data" title="Permalink to this headline">Â¶</a></h3>
<p>We will use the <a class="reference external" href="https://www.tensorflow.org/"><code class="docutils literal notranslate"><span class="pre">tensorflow</span></code></a> library to process the data and train the neural network. (Another popular library is <a class="reference external" href="https://pytorch.org/">PyTorch</a>.)</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">tensorflow.compat.v2</span> <span class="k">as</span> <span class="nn">tf</span>  <span class="c1"># explicitly use tensorflow version 2</span>
</pre></div>
</div>
</div>
</div>
<p>Each pixel is stored as an integer from <span class="math notranslate nohighlight">\(\Set{0,\dots,255}\)</span> (<span class="math notranslate nohighlight">\(2^8\)</span> possible values). However, for computations by the neural network, we need to convert it to a floating point number. We will also normalize each pixel value to be within the unit interval <span class="math notranslate nohighlight">\([0,1]\)</span>:</p>
<div class="amsmath math notranslate nohighlight" id="equation-06adcaa5-ad12-4eb7-8355-16add385b704">
<span class="eqno">(23)<a class="headerlink" href="#equation-06adcaa5-ad12-4eb7-8355-16add385b704" title="Permalink to this equation">Â¶</a></span>\[\begin{align} 
v \mapsto \frac{v - v_{\min}}{v_{\max} - v_{\min}} = \frac{v}{255}\tag{min-max normalization}
\end{align}\]</div>
<p><strong>Exercise</strong> Using the function <code class="docutils literal notranslate"><span class="pre">map</span></code>, normalize each element of an image to the unit interval <span class="math notranslate nohighlight">\([0,1]\)</span> after converting them to <code class="docutils literal notranslate"><span class="pre">tf.float32</span></code> using <a class="reference external" href="https://www.tensorflow.org/api_docs/python/tf/cast"><code class="docutils literal notranslate"><span class="pre">tf.cast</span></code></a>.</p>
<p><em>Hint:</em> The normalization factor is NOT 256. You code may look like</p>
<div class="highlight-Python notranslate"><div class="highlight"><pre><span></span><span class="o">...</span>
        <span class="n">ds_n</span><span class="p">[</span><span class="n">part</span><span class="p">]</span> <span class="o">=</span> <span class="n">ds</span><span class="p">[</span><span class="n">part</span><span class="p">]</span><span class="o">.</span><span class="n">map</span><span class="p">(</span>
                    <span class="k">lambda</span> <span class="n">image</span><span class="p">,</span> <span class="n">label</span><span class="p">:</span> <span class="p">(</span><span class="n">_____</span><span class="p">(</span><span class="n">image</span><span class="p">,</span> <span class="n">_____</span><span class="p">)</span> <span class="o">/</span> <span class="n">___</span><span class="p">,</span> <span class="n">label</span><span class="p">),</span>
                    <span class="n">num_parallel_calls</span><span class="o">=</span><span class="n">tf</span><span class="o">.</span><span class="n">data</span><span class="o">.</span><span class="n">experimental</span><span class="o">.</span><span class="n">AUTOTUNE</span><span class="p">)</span>
<span class="o">...</span>
</pre></div>
</div>
<p>and the output image should look like
<img alt="mnist_example" src="../_images/mnist_example_normalized.svg" /></p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="k">def</span> <span class="nf">normalize_mnist</span><span class="p">(</span><span class="n">ds</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">  Returns:</span>
<span class="sd">  MNIST Dataset with image pixel values normalized to float32 in [0,1].</span>
<span class="sd">  &quot;&quot;&quot;</span>
    <span class="n">ds_n</span> <span class="o">=</span> <span class="nb">dict</span><span class="o">.</span><span class="n">fromkeys</span><span class="p">(</span><span class="n">ds</span><span class="o">.</span><span class="n">keys</span><span class="p">())</span>  <span class="c1"># initialize the normalized dataset</span>
    <span class="k">for</span> <span class="n">part</span> <span class="ow">in</span> <span class="n">ds</span><span class="o">.</span><span class="n">keys</span><span class="p">():</span>
        <span class="c1"># normalize pixel values to [0,1]</span>
        <span class="c1"># YOUR CODE HERE</span>
        <span class="k">raise</span> <span class="ne">NotImplementedError</span><span class="p">()</span>
    <span class="k">return</span> <span class="n">ds_n</span>


<span class="n">ds_n</span> <span class="o">=</span> <span class="n">normalize_mnist</span><span class="p">(</span><span class="n">ds</span><span class="p">)</span>
<span class="n">pp</span><span class="o">.</span><span class="n">pprint</span><span class="p">(</span><span class="n">ds_n</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">figure</span><span class="p">(</span><span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">11</span><span class="p">,</span> <span class="mi">11</span><span class="p">),</span> <span class="n">dpi</span><span class="o">=</span><span class="mi">80</span><span class="p">)</span>
<span class="k">for</span> <span class="n">example</span> <span class="ow">in</span> <span class="n">ds_n</span><span class="p">[</span><span class="s2">&quot;train&quot;</span><span class="p">]</span><span class="o">.</span><span class="n">take</span><span class="p">(</span><span class="mi">1</span><span class="p">):</span>
    <span class="n">plot_mnist_image</span><span class="p">(</span><span class="n">example</span><span class="p">,</span>
                     <span class="n">pixel_format</span><span class="o">=</span><span class="s1">&#39;</span><span class="si">{:.2f}</span><span class="s1">&#39;</span><span class="p">)</span>  <span class="c1"># show pixel value to 2 d.p.s</span>
<span class="n">plt</span><span class="o">.</span><span class="n">savefig</span><span class="p">(</span><span class="s1">&#39;mnist_example_normalized.svg&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># tests</span>
</pre></div>
</div>
</div>
</div>
<p>To avoid overfitting, the training of a neural network uses <em>stochastic gradient descent</em> which</p>
<ul class="simple">
<li><p>divides the training into many steps where</p></li>
<li><p>each step uses a <em>randomly</em> selected minibatch of samples</p></li>
<li><p>to improve the neural network <em>bit-by-bit</em>.</p></li>
</ul>
<p>The following code specifies the batch size and enables caching and prefetching to reduce the latency in loading examples repeatedly for training and testing.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="k">def</span> <span class="nf">batch_mnist</span><span class="p">(</span><span class="n">ds_n</span><span class="p">):</span>
    <span class="n">ds_b</span> <span class="o">=</span> <span class="nb">dict</span><span class="o">.</span><span class="n">fromkeys</span><span class="p">(</span><span class="n">ds_n</span><span class="o">.</span><span class="n">keys</span><span class="p">())</span>  <span class="c1"># initialize the batched dataset</span>
    <span class="k">for</span> <span class="n">part</span> <span class="ow">in</span> <span class="n">ds_n</span><span class="o">.</span><span class="n">keys</span><span class="p">():</span>
        <span class="n">ds_b</span><span class="p">[</span><span class="n">part</span><span class="p">]</span> <span class="o">=</span> <span class="p">(</span>
            <span class="n">ds_n</span><span class="p">[</span><span class="n">part</span><span class="p">]</span><span class="o">.</span><span class="n">batch</span><span class="p">(</span>
                <span class="mi">128</span><span class="p">)</span>  <span class="c1"># Use a minibatch of examples for each training step</span>
            <span class="o">.</span><span class="n">shuffle</span><span class="p">(</span>
                <span class="n">ds_info</span><span class="o">.</span><span class="n">splits</span><span class="p">[</span><span class="n">part</span><span class="p">]</span><span class="o">.</span><span class="n">num_examples</span><span class="p">,</span>
                <span class="n">reshuffle_each_iteration</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>  <span class="c1"># shuffle data for each epoch</span>
            <span class="o">.</span><span class="n">cache</span><span class="p">()</span>  <span class="c1"># cache current elements </span>
            <span class="o">.</span><span class="n">prefetch</span><span class="p">(</span><span class="n">tf</span><span class="o">.</span><span class="n">data</span><span class="o">.</span><span class="n">experimental</span><span class="o">.</span><span class="n">AUTOTUNE</span><span class="p">)</span>
        <span class="p">)</span>  <span class="c1"># preload subsequent elements</span>
    <span class="k">return</span> <span class="n">ds_b</span>


<span class="n">ds_b</span> <span class="o">=</span> <span class="n">batch_mnist</span><span class="p">(</span><span class="n">ds_n</span><span class="p">)</span>
<span class="n">pp</span><span class="o">.</span><span class="n">pprint</span><span class="p">(</span><span class="n">ds_b</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<p><strong>Exercise</strong> The output to the above cell should look like</p>
<div class="highlight-Python notranslate"><div class="highlight"><pre><span></span><span class="p">{</span><span class="s1">&#39;test&#39;</span><span class="p">:</span> <span class="o">&lt;</span><span class="n">PrefetchDataset</span> <span class="n">shapes</span><span class="p">:</span> <span class="p">((</span><span class="kc">None</span><span class="p">,</span> <span class="mi">28</span><span class="p">,</span> <span class="mi">28</span><span class="p">,</span> <span class="mi">1</span><span class="p">),</span> <span class="p">(</span><span class="kc">None</span><span class="p">,)),</span> <span class="n">types</span><span class="p">:</span> <span class="p">(</span><span class="n">tf</span><span class="o">.</span><span class="n">float32</span><span class="p">,</span> <span class="n">tf</span><span class="o">.</span><span class="n">int64</span><span class="p">)</span><span class="o">&gt;</span><span class="p">,</span>
 <span class="s1">&#39;train&#39;</span><span class="p">:</span> <span class="o">&lt;</span><span class="n">PrefetchDataset</span> <span class="n">shapes</span><span class="p">:</span> <span class="p">((</span><span class="kc">None</span><span class="p">,</span> <span class="mi">28</span><span class="p">,</span> <span class="mi">28</span><span class="p">,</span> <span class="mi">1</span><span class="p">),</span> <span class="p">(</span><span class="kc">None</span><span class="p">,)),</span> <span class="n">types</span><span class="p">:</span> <span class="p">(</span><span class="n">tf</span><span class="o">.</span><span class="n">float32</span><span class="p">,</span> <span class="n">tf</span><span class="o">.</span><span class="n">int64</span><span class="p">)</span><span class="o">&gt;</span><span class="p">}</span>
</pre></div>
</div>
<p>with a new first dimension of unknown size <code class="docutils literal notranslate"><span class="pre">None</span></code>. Why?</p>
<p>YOUR ANSWER HERE</p>
</div>
</div>
<div class="section" id="training-and-testing">
<h2>Training and Testing<a class="headerlink" href="#training-and-testing" title="Permalink to this headline">Â¶</a></h2>
<div class="section" id="define-the-neural-network-architecture">
<h3>Define the neural network architecture<a class="headerlink" href="#define-the-neural-network-architecture" title="Permalink to this headline">Â¶</a></h3>
<p>As mentioned earlier, the neural network computes an estimate <span class="math notranslate nohighlight">\(q_{\R{y}|\RM{x}}(y|\M{x})\)</span> of the unknown probability <span class="math notranslate nohighlight">\(p_{\R{y}|\RM{x}}(y|\M{x})\)</span> for any image <span class="math notranslate nohighlight">\(\M{x}\in \mc{X}\)</span> and label <span class="math notranslate nohighlight">\(y\in \mc{Y}\)</span>. The computation is organized into layers of computation units called the <em>neurons</em>.</p>
<p>For <span class="math notranslate nohighlight">\(\ell\in \{0,\dots,L\}\)</span> and integer <span class="math notranslate nohighlight">\(L\geq 1\)</span>, let</p>
<ul class="simple">
<li><p><span class="math notranslate nohighlight">\(\M{a}^{(\ell)}\)</span> be the output of the <span class="math notranslate nohighlight">\(\ell\)</span>-th layer of the neural network, and</p></li>
<li><p><span class="math notranslate nohighlight">\(a^{(\ell)}_i\)</span> be the <span class="math notranslate nohighlight">\(i\)</span>-th element of <span class="math notranslate nohighlight">\(\M{a}^{(\ell)}\)</span>. The element is computed from the output <span class="math notranslate nohighlight">\(\M{a}^{(\ell-1)}\)</span> of its previous layer except for <span class="math notranslate nohighlight">\(\ell=0\)</span>.</p></li>
</ul>
<p>The <span class="math notranslate nohighlight">\(0\)</span>-th layer is called the <em>input layer</em> while the <span class="math notranslate nohighlight">\(L\)</span>-th layer is called the <em>output layer</em>. All other layers are called the <em>hidden layers</em>.</p>
<p>A basic neural network architecture computes <span class="math notranslate nohighlight">\(q_{\R{y}|\RM{x}}(y|\M{x})\)</span> as</p>
<div class="amsmath math notranslate nohighlight" id="equation-0c6dac35-1a8a-49b0-b1cd-9676395f541b">
<span class="eqno">(24)<a class="headerlink" href="#equation-0c6dac35-1a8a-49b0-b1cd-9676395f541b" title="Permalink to this equation">Â¶</a></span>\[\begin{align}
[q_{\R{y}|\RM{x}}(y|\M{x})]_{y\in \mc{Y}} &amp;:= \M{a}^{(L)} 
\end{align}\]</div>
<p>where</p>
<div class="amsmath math notranslate nohighlight" id="equation-d65f1318-968b-40ba-bec2-52740f4337c5">
<span class="eqno">(25)<a class="headerlink" href="#equation-d65f1318-968b-40ba-bec2-52740f4337c5" title="Permalink to this equation">Â¶</a></span>\[\begin{align}
\M{a}^{(\ell)}&amp;:=\begin{cases}
\M{x} &amp; \ell=0\\
\sigma^{(\ell)}(\overbrace{\M{W}^{(\ell)}\M{a}^{(\ell-1)}+\M{b}^{(\ell)}}^{\RM{z}^{(\ell)}:=})&amp; \ell&gt;0;
\end{cases}\tag{net}
\end{align}\]</div>
<ul class="simple">
<li><p><span class="math notranslate nohighlight">\(\M{W}^{(\ell)}\)</span> is a matrix of weights;</p></li>
<li><p><span class="math notranslate nohighlight">\(\M{b}^{(\ell)}\)</span> is a vector called bias; and</p></li>
<li><p><span class="math notranslate nohighlight">\(\sigma^{(\ell)}\)</span> is a reveal-valued function called the <em>activation function</em>.</p></li>
</ul>
<p>To ensure <span class="math notranslate nohighlight">\(\M{a}^{(L)}\)</span> is a valid probability vector, the soft-max activation function is often used for the last layer:</p>
<div class="math notranslate nohighlight">
\[\begin{split} \sigma^{(L)}\left(\left[\begin{smallmatrix}z^{(\ell)}_1 \\ \vdots \\ z^{(\ell)}_k\end{smallmatrix}\right]\right) := \frac{1}{\sum_{i=1}^k e^{z^{(\ell)}_i}} \left[\begin{smallmatrix}e^{z^{(\ell)}_1} \\ \vdots \\ e^{z^{(\ell)}_k}\end{smallmatrix}\right] \end{split}\]</div>
<p>where <span class="math notranslate nohighlight">\(k:=\abs{\mc{Y}}=10\)</span> is the number of distinct class labels.</p>
<p>This ensures <span class="math notranslate nohighlight">\(\M{a}^{(L)}\)</span> (the output of soft-max) is stochastic, i.e.,</p>
<div class="math notranslate nohighlight">
\[\sum_{i=1}^k a_i^{(L)}  = 1\kern1em \text{and} \kern1em a_i^{(L)}\geq 0\qquad \forall i\in \{1,\dots,k\}.\]</div>
<p>The activation functions <span class="math notranslate nohighlight">\(\sigma^{(\ell)}\)</span> for other layers <span class="math notranslate nohighlight">\(1\leq \ell&lt;L\)</span> is often the vectorized version of</p>
<ul class="simple">
<li><p>sigmoid:</p></li>
</ul>
<div class="math notranslate nohighlight">
\[\sigma_{\text{sigmoid}}(z) = \frac{1}{1+e^{-z}}\]</div>
<ul class="simple">
<li><p>rectified linear unit (ReLU):</p></li>
</ul>
<div class="math notranslate nohighlight">
\[ \sigma_{\text{ReLU}}(z) = \max\{0,z\}. \]</div>
<div class="cell tag_hide-input docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="o">%%html</span>
<span class="p">&lt;</span><span class="nt">b</span><span class="p">&gt;</span>Activation function:<span class="p">&lt;/</span><span class="nt">b</span><span class="p">&gt;&lt;</span><span class="nt">br</span><span class="p">&gt;</span>
<span class="p">&lt;</span><span class="nt">iframe</span> <span class="na">width</span><span class="o">=</span><span class="s">&quot;805&quot;</span> <span class="na">height</span><span class="o">=</span><span class="s">&quot;450&quot;</span> <span class="na">src</span><span class="o">=</span><span class="s">&quot;https://www.youtube.com/embed/aircAruvnKk?start=649&amp;end=695&quot;</span> <span class="na">frameborder</span><span class="o">=</span><span class="s">&quot;0&quot;</span> <span class="na">allow</span><span class="o">=</span><span class="s">&quot;accelerometer; autoplay; encrypted-media; gyroscope; picture-in-picture&quot;</span> <span class="na">allowfullscreen</span><span class="p">&gt;&lt;/</span><span class="nt">iframe</span><span class="p">&gt;</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_html"><b>Activation function:</b><br>
<iframe width="805" height="450" src="https://www.youtube.com/embed/aircAruvnKk?start=649&end=695" frameborder="0" allow="accelerometer; autoplay; encrypted-media; gyroscope; picture-in-picture" allowfullscreen></iframe>
</div></div>
</div>
<p>The following plots the ReLU activation function.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="k">def</span> <span class="nf">ReLU</span><span class="p">(</span><span class="n">z</span><span class="p">):</span>
    <span class="k">return</span> <span class="n">np</span><span class="o">.</span><span class="n">max</span><span class="p">([</span><span class="n">np</span><span class="o">.</span><span class="n">zeros</span><span class="p">(</span><span class="n">z</span><span class="o">.</span><span class="n">shape</span><span class="p">),</span> <span class="n">z</span><span class="p">],</span> <span class="n">axis</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>


<span class="n">z</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">linspace</span><span class="p">(</span><span class="o">-</span><span class="mi">5</span><span class="p">,</span> <span class="mi">5</span><span class="p">,</span> <span class="mi">100</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">z</span><span class="p">,</span> <span class="n">ReLU</span><span class="p">(</span><span class="n">z</span><span class="p">))</span>
<span class="n">plt</span><span class="o">.</span><span class="n">xlim</span><span class="p">(</span><span class="o">-</span><span class="mi">5</span><span class="p">,</span> <span class="mi">5</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">title</span><span class="p">(</span><span class="sa">r</span><span class="s1">&#39;ReLU: $\max\{0,z\}$&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">xlabel</span><span class="p">(</span><span class="sa">r</span><span class="s1">&#39;$z$&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
</pre></div>
</div>
</div>
</div>
<p><strong>Exercise</strong> Complete the vectorized function <code class="docutils literal notranslate"><span class="pre">sigmoid</span></code> using the vectorized exponentiation <code class="docutils literal notranslate"><span class="pre">np.exp</span></code>.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="k">def</span> <span class="nf">sigmoid</span><span class="p">(</span><span class="n">z</span><span class="p">):</span>
    <span class="c1"># YOUR CODE HERE</span>
    <span class="k">raise</span> <span class="ne">NotImplementedError</span><span class="p">()</span>


<span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">z</span><span class="p">,</span> <span class="n">ReLU</span><span class="p">(</span><span class="n">z</span><span class="p">))</span>
<span class="n">plt</span><span class="o">.</span><span class="n">xlim</span><span class="p">(</span><span class="o">-</span><span class="mi">5</span><span class="p">,</span> <span class="mi">5</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">title</span><span class="p">(</span><span class="sa">r</span><span class="s1">&#39;Sigmoid function: $\frac</span><span class="si">{1}</span><span class="s1">{1+e^{-z}}$&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">xlabel</span><span class="p">(</span><span class="sa">r</span><span class="s1">&#39;$z$&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># tests</span>
</pre></div>
</div>
</div>
</div>
<p>The following uses the <a class="reference external" href="https://keras.io/"><code class="docutils literal notranslate"><span class="pre">keras</span></code></a> library to define the basic neural network achitecture. <code class="docutils literal notranslate"><span class="pre">keras</span></code> runs on top of <code class="docutils literal notranslate"><span class="pre">tensorflow</span></code> and offers a higher-level abstraction to simplify the construction and training of a neural network. (<a class="reference external" href="https://github.com/tflearn/tflearn"><code class="docutils literal notranslate"><span class="pre">tflearn</span></code></a> is another library that provides a higher-level API for <code class="docutils literal notranslate"><span class="pre">tensorflow</span></code>.)</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="k">def</span> <span class="nf">create_simple_model</span><span class="p">():</span>
    <span class="n">tf</span><span class="o">.</span><span class="n">keras</span><span class="o">.</span><span class="n">backend</span><span class="o">.</span><span class="n">clear_session</span><span class="p">()</span> <span class="c1"># clear keras cache. </span>
                        <span class="c1"># See https://github.com/keras-team/keras/issues/7294</span>
    <span class="n">model</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">keras</span><span class="o">.</span><span class="n">models</span><span class="o">.</span><span class="n">Sequential</span><span class="p">([</span>
        <span class="n">tf</span><span class="o">.</span><span class="n">keras</span><span class="o">.</span><span class="n">layers</span><span class="o">.</span><span class="n">Flatten</span><span class="p">(</span><span class="n">input_shape</span><span class="o">=</span><span class="p">(</span><span class="mi">28</span><span class="p">,</span> <span class="mi">28</span><span class="p">,</span> <span class="mi">1</span><span class="p">)),</span>
        <span class="n">tf</span><span class="o">.</span><span class="n">keras</span><span class="o">.</span><span class="n">layers</span><span class="o">.</span><span class="n">Dense</span><span class="p">(</span><span class="mi">16</span><span class="p">,</span> <span class="n">activation</span><span class="o">=</span><span class="n">tf</span><span class="o">.</span><span class="n">keras</span><span class="o">.</span><span class="n">activations</span><span class="o">.</span><span class="n">relu</span><span class="p">),</span>
        <span class="n">tf</span><span class="o">.</span><span class="n">keras</span><span class="o">.</span><span class="n">layers</span><span class="o">.</span><span class="n">Dense</span><span class="p">(</span><span class="mi">16</span><span class="p">,</span> <span class="n">activation</span><span class="o">=</span><span class="n">tf</span><span class="o">.</span><span class="n">keras</span><span class="o">.</span><span class="n">activations</span><span class="o">.</span><span class="n">relu</span><span class="p">),</span>
        <span class="n">tf</span><span class="o">.</span><span class="n">keras</span><span class="o">.</span><span class="n">layers</span><span class="o">.</span><span class="n">Dense</span><span class="p">(</span><span class="mi">10</span><span class="p">,</span> <span class="n">activation</span><span class="o">=</span><span class="n">tf</span><span class="o">.</span><span class="n">keras</span><span class="o">.</span><span class="n">activations</span><span class="o">.</span><span class="n">softmax</span><span class="p">)</span>
    <span class="p">],</span> <span class="s1">&#39;Simple_sequential&#39;</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">model</span>


<span class="n">model</span> <span class="o">=</span> <span class="n">create_simple_model</span><span class="p">()</span>
<span class="n">model</span><span class="o">.</span><span class="n">summary</span><span class="p">()</span>
</pre></div>
</div>
</div>
</div>
<p>The above defines <a class="reference external" href="https://www.tensorflow.org/api_docs/python/tf/keras/layers">a linear stack</a> of <a class="reference external" href="https://www.tensorflow.org/api_docs/python/tf/keras/layers/Dense">fully-connected layers</a> after <a class="reference external" href="https://www.tensorflow.org/api_docs/python/tf/keras/layers/Flatten">flattening the input</a>. The method <code class="docutils literal notranslate"><span class="pre">summary</span></code> is useful for <a class="reference external" href="https://keras.io/examples/keras_recipes/debugging_tips/">debugging in Keras</a>.</p>
<p><strong>Execise</strong> Assign to <code class="docutils literal notranslate"><span class="pre">n_hidden_layers</span></code> the number of hidden layers for the above simple sequential model.</p>
<p><em>Hint:</em> The layer <code class="docutils literal notranslate"><span class="pre">Flatten</span></code> do not counts as a hidden layer since it simply reshape the input without using any trainable parameters. The output layer also do not count as a hidden layer since its output is the output of the neural network, not intermediate (hidden) values that require further processing by the neurons.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># YOUR CODE HERE</span>
<span class="k">raise</span> <span class="ne">NotImplementedError</span><span class="p">()</span>
<span class="n">n_hidden_layers</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># tests</span>
</pre></div>
</div>
</div>
</div>
</div>
<div class="section" id="train-and-validate">
<h3>Train and validate<a class="headerlink" href="#train-and-validate" title="Permalink to this headline">Â¶</a></h3>
<p>Recall that a neural network that minimizes the cross entropy gives <span class="math notranslate nohighlight">\(p_{\R{y}|\RM{x}}(y|\RM{x})\)</span> a.s. for all <span class="math notranslate nohighlight">\(y\in \mc{Y}\)</span> and any possible input image <span class="math notranslate nohighlight">\(\RM{x}\)</span>:</p>
<div class="amsmath math notranslate nohighlight" id="equation-25b01ff6-d63d-43ec-b8a5-93d3ac5f9e32">
<span class="eqno">(26)<a class="headerlink" href="#equation-25b01ff6-d63d-43ec-b8a5-93d3ac5f9e32" title="Permalink to this equation">Â¶</a></span>\[\begin{align}
\min_{q_{\R{y}|\RM{x}}} \overbrace{\E\left[\log \frac{1}{q_{\R{y}|\RM{x}}(\R{y}|\RM{x})}\right]}^{ \text{Cross entropy}\\ H(p_{\R{y}|\RM{x}}\|q_{\R{y}|\RM{x}}|p_{\RM{x}}):=}
&amp;= H(\R{y}|\RM{x})
\end{align}\]</div>
<p>The cross entropy cannot be computed exactly without knowing the joint distribution <span class="math notranslate nohighlight">\(p_{\RM{x}\R{y}}\)</span>. Nevertheless, it can be estimated from a batch of i.i.d. samples <span class="math notranslate nohighlight">\((\RM{x}_{\R{j}_i},\R{y}_{\R{j}_i})\)</span> for <span class="math notranslate nohighlight">\(1\leq i\leq n\)</span>:</p>
<div class="amsmath math notranslate nohighlight" id="equation-ee545a6d-0cb1-42b3-8250-92e6aaf202bf">
<span class="eqno">(27)<a class="headerlink" href="#equation-ee545a6d-0cb1-42b3-8250-92e6aaf202bf" title="Permalink to this equation">Â¶</a></span>\[\begin{align}
\R{L}(\theta)&amp;:=\frac1n \sum_{i=1}^n \log \frac{1}{q_{\R{y}|\RM{x}}(\R{y}_{\R{j}_i}|\RM{x}_{\R{j}_i})}\tag{empirical loss}
\end{align}\]</div>
<p>where</p>
<div class="math notranslate nohighlight">
\[\theta := \operatorname{flat}(\M{W}^{(\ell)},\M{b}^{(\ell)}\mid 0\leq \ell \leq L)\]</div>
<p>is the vector of parameters of the neural network defined in (net).</p>
<p>A mini-batch <a class="reference external" href="https://en.wikipedia.org/wiki/Stochastic_gradient_descent">gradient descent algorithm</a> is often used to reduce the loss. It iteratively updates/trains the neural network parameters:</p>
<div class="math notranslate nohighlight">
\[\theta \leftarrow \theta -s\nabla \R{L}(\theta)\]</div>
<p>by computing the gradient <span class="math notranslate nohighlight">\(\nabla \R{L}(\theta)\)</span> on a randomly selected minibatch of examples and choosing an appropriate learning rate <span class="math notranslate nohighlight">\(s\)</span>.</p>
<p>As explained in the <a class="reference external" href="https://www.youtube.com/embed/videoseries?list=PLZHQObOWTQDNU6R1_67000Dx_ZCJB-3pi">lecture series on deep learning</a> in the introduction section:</p>
<ul class="simple">
<li><p>The gradient can be computed systematically using a technique called <em>backpropagation</em> due to the structure of the neural network in (net).</p></li>
<li><p>The learning rate can affect the convergence rate of the loss to a local minima:</p>
<ul>
<li><p><span class="math notranslate nohighlight">\(\theta\)</span> may overshoot its optimal value if <span class="math notranslate nohighlight">\(s\)</span> is too large, and</p></li>
<li><p>the convergence can be very slow if <span class="math notranslate nohighlight">\(\theta\)</span> is too small.</p></li>
</ul>
</li>
</ul>
<p>A more advanced method called <a class="reference external" href="https://en.wikipedia.org/wiki/Stochastic_gradient_descent#Adam">Adam (Adaptive Momentum Estimation)</a> can adaptively choose <span class="math notranslate nohighlight">\(s\)</span> to speed up the convergence.</p>
<div class="cell tag_hide-input docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="o">%%html</span>
<span class="p">&lt;</span><span class="nt">div</span><span class="p">&gt;</span>
<span class="p">&lt;</span><span class="nt">b</span><span class="p">&gt;</span>What is gradient descent?<span class="p">&lt;/</span><span class="nt">b</span><span class="p">&gt;&lt;</span><span class="nt">br</span><span class="p">&gt;</span>
<span class="p">&lt;</span><span class="nt">iframe</span> <span class="na">width</span><span class="o">=</span><span class="s">&quot;805&quot;</span> <span class="na">height</span><span class="o">=</span><span class="s">&quot;450&quot;</span> <span class="na">src</span><span class="o">=</span><span class="s">&quot;https://www.youtube.com/embed/IHZwWFHWa-w?start=468&amp;end=510&quot;</span> <span class="na">frameborder</span><span class="o">=</span><span class="s">&quot;0&quot;</span> <span class="na">allow</span><span class="o">=</span><span class="s">&quot;accelerometer; autoplay; encrypted-media; gyroscope; picture-in-picture&quot;</span> <span class="na">allowfullscreen</span><span class="p">&gt;&lt;/</span><span class="nt">iframe</span><span class="p">&gt;</span>
<span class="p">&lt;/</span><span class="nt">div</span><span class="p">&gt;</span>
<span class="p">&lt;</span><span class="nt">div</span><span class="p">&gt;</span>
<span class="p">&lt;</span><span class="nt">b</span><span class="p">&gt;</span>How to choose the step size?<span class="p">&lt;/</span><span class="nt">b</span><span class="p">&gt;&lt;</span><span class="nt">br</span><span class="p">&gt;</span>
<span class="p">&lt;</span><span class="nt">iframe</span> <span class="na">width</span><span class="o">=</span><span class="s">&quot;805&quot;</span> <span class="na">height</span><span class="o">=</span><span class="s">&quot;450&quot;</span> <span class="na">src</span><span class="o">=</span><span class="s">&quot;https://www.youtube.com/embed/IHZwWFHWa-w?start=403&amp;end=415&quot;</span> <span class="na">frameborder</span><span class="o">=</span><span class="s">&quot;0&quot;</span> <span class="na">allow</span><span class="o">=</span><span class="s">&quot;accelerometer; autoplay; encrypted-media; gyroscope; picture-in-picture&quot;</span> <span class="na">allowfullscreen</span><span class="p">&gt;&lt;/</span><span class="nt">iframe</span><span class="p">&gt;</span>
<span class="p">&lt;/</span><span class="nt">div</span><span class="p">&gt;</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_html"><div>
<b>What is gradient descent?</b><br>
<iframe width="805" height="450" src="https://www.youtube.com/embed/IHZwWFHWa-w?start=468&end=510" frameborder="0" allow="accelerometer; autoplay; encrypted-media; gyroscope; picture-in-picture" allowfullscreen></iframe>
</div>
<div>
<b>How to choose the step size?</b><br>
<iframe width="805" height="450" src="https://www.youtube.com/embed/IHZwWFHWa-w?start=403&end=415" frameborder="0" allow="accelerometer; autoplay; encrypted-media; gyroscope; picture-in-picture" allowfullscreen></iframe>
</div>
</div></div>
</div>
<p>The <a class="reference external" href="https://keras.io/api/losses/">loss function</a>, gradient descent algorithm, and the performance metrics can be specified using the <a class="reference external" href="https://keras.io/api/losses/"><code class="docutils literal notranslate"><span class="pre">compile</span></code> method</a>.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="k">def</span> <span class="nf">compile_model</span><span class="p">(</span><span class="n">model</span><span class="p">):</span>
    <span class="n">model</span><span class="o">.</span><span class="n">compile</span><span class="p">(</span><span class="n">loss</span><span class="o">=</span><span class="n">tf</span><span class="o">.</span><span class="n">keras</span><span class="o">.</span><span class="n">losses</span><span class="o">.</span><span class="n">SparseCategoricalCrossentropy</span><span class="p">(),</span>
                  <span class="n">optimizer</span><span class="o">=</span><span class="n">tf</span><span class="o">.</span><span class="n">keras</span><span class="o">.</span><span class="n">optimizers</span><span class="o">.</span><span class="n">Adam</span><span class="p">(</span><span class="mf">0.001</span><span class="p">),</span>
                  <span class="n">metrics</span><span class="o">=</span><span class="p">[</span><span class="n">tf</span><span class="o">.</span><span class="n">keras</span><span class="o">.</span><span class="n">metrics</span><span class="o">.</span><span class="n">SparseCategoricalAccuracy</span><span class="p">()])</span>
    <span class="k">return</span> <span class="n">model</span>

<span class="n">compile_model</span><span class="p">(</span><span class="n">model</span><span class="p">)</span>
<span class="n">model</span><span class="o">.</span><span class="n">loss</span><span class="p">,</span> <span class="n">model</span><span class="o">.</span><span class="n">optimizer</span>
</pre></div>
</div>
</div>
</div>
<p>We can now train the neural network using the method <a class="reference external" href="https://www.tensorflow.org/api_docs/python/tf/keras/Model#fit"><code class="docutils literal notranslate"><span class="pre">fit</span></code></a> of the compiled model:</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="k">if</span> <span class="nb">input</span><span class="p">(</span><span class="s1">&#39;Train? [Y/n]&#39;</span><span class="p">)</span><span class="o">.</span><span class="n">lower</span><span class="p">()</span> <span class="o">!=</span> <span class="s1">&#39;n&#39;</span><span class="p">:</span>
    <span class="n">model</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">ds_b</span><span class="p">[</span><span class="s2">&quot;train&quot;</span><span class="p">])</span>
</pre></div>
</div>
</div>
</div>
<p><strong>Exercise</strong> By default, the neural network is trained for 1 epoch. What happens to the training accuracy if you rerun the above cell to train the model for another epoch?</p>
<p>YOUR ANSWER HERE</p>
<p>We can set the parameter <code class="docutils literal notranslate"><span class="pre">epochs</span></code> to train the neural network for multiple epochs since it is quite unlikely to train a neural network well with just one epoch. To determine whether the neural network is well-trained (when to stop training), we should also use a separate validation set to evaluate the performance of the neural network. The validation set can be specified using the parameter <code class="docutils literal notranslate"><span class="pre">validation_set</span></code> as follows:</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="k">if</span> <span class="nb">input</span><span class="p">(</span><span class="s1">&#39;Train? [Y/n]&#39;</span><span class="p">)</span><span class="o">.</span><span class="n">lower</span><span class="p">()</span> <span class="o">!=</span> <span class="s1">&#39;n&#39;</span><span class="p">:</span>
    <span class="n">model</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">ds_b</span><span class="p">[</span><span class="s2">&quot;train&quot;</span><span class="p">],</span> <span class="n">epochs</span><span class="o">=</span><span class="mi">6</span><span class="p">,</span> <span class="n">validation_data</span><span class="o">=</span><span class="n">ds_b</span><span class="p">[</span><span class="s2">&quot;test&quot;</span><span class="p">])</span>
</pre></div>
</div>
</div>
</div>
<p><strong>Exercise</strong> Is the maximum validation accuracy <code class="docutils literal notranslate"><span class="pre">val_sparse_categorical_accuracy</span></code> (over different epoches) an unbiased estimate of the performance of deep learning for the given dataset? If not, how to avoid the bias?</p>
<p>YOUR ANSWER HERE</p>
<p><strong>Exercise</strong> Is it a good idea to use cross-validation to evaluate the neural network? Why or why not?</p>
<p>YOUR ANSWER HERE</p>
</div>
<div class="section" id="log-the-results">
<h3>Log the results<a class="headerlink" href="#log-the-results" title="Permalink to this headline">Â¶</a></h3>
<p>To call additional functions during training, we can add the functions to the <code class="docutils literal notranslate"><span class="pre">callbacks</span></code> parameter of the model <code class="docutils literal notranslate"><span class="pre">fit</span></code> method. For instance:</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">tqdm.keras</span>

<span class="k">if</span> <span class="nb">input</span><span class="p">(</span><span class="s1">&#39;Train? [Y/n]&#39;</span><span class="p">)</span><span class="o">.</span><span class="n">lower</span><span class="p">()</span> <span class="o">!=</span> <span class="s1">&#39;n&#39;</span><span class="p">:</span>
    <span class="n">model</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">ds_b</span><span class="p">[</span><span class="s2">&quot;train&quot;</span><span class="p">],</span>
              <span class="n">epochs</span><span class="o">=</span><span class="mi">6</span><span class="p">,</span>
              <span class="n">validation_data</span><span class="o">=</span><span class="n">ds_b</span><span class="p">[</span><span class="s2">&quot;test&quot;</span><span class="p">],</span>
              <span class="n">verbose</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span>
              <span class="n">callbacks</span><span class="o">=</span><span class="p">[</span><span class="n">tqdm</span><span class="o">.</span><span class="n">keras</span><span class="o">.</span><span class="n">TqdmCallback</span><span class="p">(</span><span class="n">verbose</span><span class="o">=</span><span class="mi">2</span><span class="p">)])</span>
</pre></div>
</div>
</div>
</div>
<p>The above code uses <a class="reference external" href="https://tqdm.github.io/docs/keras/"><code class="docutils literal notranslate"><span class="pre">tqdm.keras.TqdmCallback()</span></code></a> to return a callback function that displays a graphical progress bar:</p>
<ul class="simple">
<li><p>Setting <code class="docutils literal notranslate"><span class="pre">verbose=0</span></code> for the method <code class="docutils literal notranslate"><span class="pre">fit</span></code> disables the default text-based progress bar.</p></li>
<li><p>Setting <code class="docutils literal notranslate"><span class="pre">verbose=2</span></code> for the class <code class="docutils literal notranslate"><span class="pre">TqdmCallback</span></code> show and keep the progress bars for training each batch. Try changing <code class="docutils literal notranslate"><span class="pre">verbose</span></code> to other values to see different effects.</p></li>
</ul>
<p>An import use of callback functions is to save the models and results during training for further analysis. We define the following function <code class="docutils literal notranslate"><span class="pre">train_model</span></code> for this purpose:</p>
<ul class="simple">
<li><p>Take a look at the docstring to learn its basic usage, and then</p></li>
<li><p>learn the implementations in the source code.</p></li>
</ul>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">os</span><span class="o">,</span> <span class="nn">datetime</span><span class="o">,</span> <span class="nn">pytz</span>


<span class="k">def</span> <span class="nf">train_model</span><span class="p">(</span><span class="n">model</span><span class="p">,</span>
                <span class="n">fit_params</span><span class="o">=</span><span class="p">{},</span>
                <span class="n">log_root</span><span class="o">=</span><span class="s1">&#39;.&#39;</span><span class="p">,</span>
                <span class="n">save_log_params</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
                <span class="n">save_model_params</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
                <span class="n">debug_params</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
    <span class="sd">&#39;&#39;&#39;Train and test the model, and return the log directory path name.</span>
<span class="sd">    </span>
<span class="sd">    Parameters:</span>
<span class="sd">    ----------</span>
<span class="sd">    log_root (str): the root directory for creating log directory</span>
<span class="sd">    </span>
<span class="sd">    fit_params (dict): dictionary of parameters to pass to model.fit.</span>
<span class="sd">    save_log_params (dict): dictionary of parameters to pass to </span>
<span class="sd">        tf.keras.callbacks.TensorBoard to save the results for TensorBoard.</span>
<span class="sd">        The default value None means no logging of the results.</span>
<span class="sd">    save_model_params (dict): dictionary of parameters to pass to</span>
<span class="sd">        tf.keras.callbacks.ModelCheckpoint to save the model to checkpoint </span>
<span class="sd">        files. </span>
<span class="sd">        The default value None means no saving of the models.</span>
<span class="sd">    debug_params (dict): dictionary of parameters to pass to </span>
<span class="sd">        tf.debugging.experimental.enable_dump_debug_info for debugger </span>
<span class="sd">        v2 in tensorboard.</span>
<span class="sd">        The default value None means no logging of the debug information.</span>
<span class="sd">        </span>
<span class="sd">    Returns:</span>
<span class="sd">    -------</span>
<span class="sd">    str: log directory path that points to a subfolder of log_root named </span>
<span class="sd">        using the current time.</span>
<span class="sd">    &#39;&#39;&#39;</span>
    <span class="c1"># use a subfolder named by the current time to distinguish repeated runs</span>
    <span class="n">log_dir</span> <span class="o">=</span> <span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">join</span><span class="p">(</span>
        <span class="n">log_root</span><span class="p">,</span>
        <span class="n">datetime</span><span class="o">.</span><span class="n">datetime</span><span class="o">.</span><span class="n">now</span><span class="p">(</span>
            <span class="n">tz</span><span class="o">=</span><span class="n">pytz</span><span class="o">.</span><span class="n">timezone</span><span class="p">(</span><span class="s1">&#39;Asia/Hong_Kong&#39;</span><span class="p">))</span><span class="o">.</span><span class="n">strftime</span><span class="p">(</span><span class="s2">&quot;%Y%m</span><span class="si">%d</span><span class="s2">-%H%M%S&quot;</span><span class="p">))</span>
    
    <span class="n">callbacks</span> <span class="o">=</span> <span class="n">fit_params</span><span class="o">.</span><span class="n">pop</span><span class="p">(</span><span class="s1">&#39;callbacks&#39;</span><span class="p">,</span> <span class="p">[])</span><span class="o">.</span><span class="n">copy</span><span class="p">()</span>
    
    <span class="k">if</span> <span class="n">save_log_params</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
        <span class="c1"># add callback to save the training log for further analysis by tensorboard</span>
        <span class="n">callbacks</span><span class="o">.</span><span class="n">append</span><span class="p">(</span>
            <span class="n">tf</span><span class="o">.</span><span class="n">keras</span><span class="o">.</span><span class="n">callbacks</span><span class="o">.</span><span class="n">TensorBoard</span><span class="p">(</span><span class="n">log_dir</span><span class="p">,</span>
                                           <span class="o">**</span><span class="n">save_log_params</span><span class="p">))</span>

    <span class="k">if</span> <span class="n">save_model_params</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
        <span class="c1"># save the model as checkpoint files after each training epoch</span>
        <span class="n">callbacks</span><span class="o">.</span><span class="n">append</span><span class="p">(</span>
            <span class="n">tf</span><span class="o">.</span><span class="n">keras</span><span class="o">.</span><span class="n">callbacks</span><span class="o">.</span><span class="n">ModelCheckpoint</span><span class="p">(</span><span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="n">log_dir</span><span class="p">,</span> <span class="s1">&#39;</span><span class="si">{epoch}</span><span class="s1">.ckpt&#39;</span><span class="p">),</span>
                                               <span class="o">**</span><span class="n">save_model_params</span><span class="p">))</span>

    <span class="k">if</span> <span class="n">debug_params</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
        <span class="c1"># save information for debugger v2 in tensorboard</span>
        <span class="n">tf</span><span class="o">.</span><span class="n">debugging</span><span class="o">.</span><span class="n">experimental</span><span class="o">.</span><span class="n">enable_dump_debug_info</span><span class="p">(</span>
            <span class="n">log_dir</span><span class="p">,</span> <span class="o">**</span><span class="n">debug_params</span><span class="p">)</span>

    <span class="c1"># training + testing (validation)</span>
    <span class="n">model</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">ds_b</span><span class="p">[</span><span class="s1">&#39;train&#39;</span><span class="p">],</span>
              <span class="n">validation_data</span><span class="o">=</span><span class="n">ds_b</span><span class="p">[</span><span class="s1">&#39;test&#39;</span><span class="p">],</span>
              <span class="n">callbacks</span><span class="o">=</span><span class="n">callbacks</span><span class="p">,</span>
              <span class="o">**</span><span class="n">fit_params</span><span class="p">)</span>

    <span class="k">return</span> <span class="n">log_dir</span>
</pre></div>
</div>
</div>
</div>
<p>For example:</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">fit_params</span> <span class="o">=</span> <span class="p">{</span><span class="s1">&#39;epochs&#39;</span><span class="p">:</span> <span class="mi">6</span><span class="p">,</span> <span class="s1">&#39;callbacks&#39;</span><span class="p">:</span> <span class="p">[</span><span class="n">tqdm</span><span class="o">.</span><span class="n">keras</span><span class="o">.</span><span class="n">TqdmCallback</span><span class="p">()],</span> <span class="s1">&#39;verbose&#39;</span><span class="p">:</span> <span class="mi">0</span><span class="p">}</span>
<span class="n">log_root</span> <span class="o">=</span> <span class="s1">&#39;private/demo/&#39;</span>
<span class="n">save_log_params</span> <span class="o">=</span> <span class="p">{</span><span class="s1">&#39;update_freq&#39;</span><span class="p">:</span> <span class="mi">100</span><span class="p">,</span> <span class="s1">&#39;histogram_freq&#39;</span><span class="p">:</span> <span class="mi">1</span><span class="p">}</span>
<span class="n">save_model_params</span> <span class="o">=</span> <span class="p">{</span><span class="s1">&#39;save_weights_only&#39;</span><span class="p">:</span> <span class="kc">True</span><span class="p">,</span> <span class="s1">&#39;verbose&#39;</span><span class="p">:</span> <span class="mi">1</span><span class="p">}</span>
<span class="n">debug_params</span> <span class="o">=</span> <span class="p">{</span><span class="s1">&#39;tensor_debug_mode&#39;</span><span class="p">:</span> <span class="s2">&quot;FULL_HEALTH&quot;</span><span class="p">,</span> <span class="s1">&#39;circular_buffer_size&#39;</span><span class="p">:</span> <span class="o">-</span><span class="mi">1</span><span class="p">}</span>

<span class="k">if</span> <span class="nb">input</span><span class="p">(</span><span class="s1">&#39;Train? [Y/n]&#39;</span><span class="p">)</span><span class="o">.</span><span class="n">lower</span><span class="p">()</span> <span class="o">!=</span> <span class="s1">&#39;n&#39;</span><span class="p">:</span>
    <span class="n">model</span> <span class="o">=</span> <span class="n">compile_model</span><span class="p">(</span><span class="n">create_simple_model</span><span class="p">())</span>
    <span class="n">log_dir</span> <span class="o">=</span> <span class="n">train_model</span><span class="p">(</span><span class="n">model</span><span class="p">,</span>
                          <span class="n">fit_params</span> <span class="o">=</span> <span class="n">fit_params</span><span class="p">,</span>
                          <span class="n">log_root</span><span class="o">=</span><span class="n">log_root</span><span class="p">,</span>
                          <span class="n">save_log_params</span><span class="o">=</span><span class="n">save_log_params</span><span class="p">,</span>
                          <span class="n">save_model_params</span><span class="o">=</span><span class="n">save_model_params</span><span class="p">,</span>
                          <span class="n">debug_params</span><span class="o">=</span><span class="n">debug_params</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<p>By providing the <code class="docutils literal notranslate"><span class="pre">save_model_params</span></code> to the callback <a class="reference external" href="https://www.tensorflow.org/tutorials/keras/save_and_load#save_checkpoints_during_training"><code class="docutils literal notranslate"><span class="pre">tf.keras.callbacks.ModelCheckpoint</span></code></a>, the model is saved at the end of each epoch to <code class="docutils literal notranslate"><span class="pre">log_dir</span></code>.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="o">!</span>ls <span class="o">{</span>log_dir<span class="o">}</span>
</pre></div>
</div>
</div>
</div>
<p>Saving the model is useful because it often takes a long time to train a neural network. To reload the model from the latest checkpoint and continue to train it:</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="k">if</span> <span class="nb">input</span><span class="p">(</span><span class="s1">&#39;Continue to train? [Y/n]&#39;</span><span class="p">)</span><span class="o">.</span><span class="n">lower</span><span class="p">()</span> <span class="o">!=</span> <span class="s1">&#39;n&#39;</span><span class="p">:</span>
    <span class="c1"># load the weights of the previously trained model</span>
    <span class="n">restored_model</span> <span class="o">=</span> <span class="n">compile_model</span><span class="p">(</span><span class="n">create_simple_model</span><span class="p">())</span>
    <span class="n">restored_model</span><span class="o">.</span><span class="n">load_weights</span><span class="p">(</span><span class="n">tf</span><span class="o">.</span><span class="n">train</span><span class="o">.</span><span class="n">latest_checkpoint</span><span class="p">(</span><span class="n">log_dir</span><span class="p">))</span>    
    <span class="c1"># continue to train</span>
    <span class="n">train_model</span><span class="p">(</span><span class="n">restored_model</span><span class="p">,</span> 
                <span class="n">log_root</span><span class="o">=</span><span class="n">log_root</span><span class="p">,</span> 
                <span class="n">save_log_params</span><span class="o">=</span><span class="n">save_log_params</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<p>By providing <a class="reference external" href="https://www.tensorflow.org/tensorboard/get_started#using_tensorboard_with_keras_modelfit"><code class="docutils literal notranslate"><span class="pre">tf.keras.callbacks.TensorBoard</span></code></a> as a callback function to the <code class="docutils literal notranslate"><span class="pre">fit</span></code> method earlier, the training logs can be analyzed using TensorBoard.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="k">if</span> <span class="nb">input</span><span class="p">(</span><span class="s1">&#39;Execute? [Y/n]&#39;</span><span class="p">)</span><span class="o">.</span><span class="n">lower</span><span class="p">()</span> <span class="o">!=</span> <span class="s1">&#39;n&#39;</span><span class="p">:</span>
    <span class="o">%</span><span class="k">load_ext</span> tensorboard
    <span class="o">%</span><span class="k">tensorboard</span> --logdir {log_dir}
</pre></div>
</div>
</div>
</div>
<p>The <code class="docutils literal notranslate"><span class="pre">SCALARS</span></code> tab shows the curves of training and validation losses/accuracies after different batches/epoches. The curves often have jitters as the gradient descent is stochastic (random). To see the typical performance, a smoothing factor <span class="math notranslate nohighlight">\(\theta\in [0,1]\)</span> can be applied on the left panel. The smoothed curve <span class="math notranslate nohighlight">\(\bar{l}(t)\)</span> of the original curve <span class="math notranslate nohighlight">\(l(t)\)</span> is defined as</p>
<div class="amsmath math notranslate nohighlight" id="equation-bceaf89a-3983-4bcd-9c4a-044253ccf5bb">
<span class="eqno">(28)<a class="headerlink" href="#equation-bceaf89a-3983-4bcd-9c4a-044253ccf5bb" title="Permalink to this equation">Â¶</a></span>\[\begin{align}
\bar{l}(t) = \theta \bar{l}(t-1) + (1-\theta) l(t)
\end{align}\]</div>
<p>which is called the moving average. Try changing the smoothing factor on the left panel to see the effect.</p>
<p><strong>Exercise</strong>  If the smoothing factor <span class="math notranslate nohighlight">\(\theta\)</span> is too large, would it cause bias when using empirical loss or performance to estimate the actual loss or performance? If so, is estimate overly optimistic or pessimistic?</p>
<p>YOUR ANSWER HERE</p>
<p>We can also visualize the input images in TensorBoard:</p>
<ul class="simple">
<li><p>Run the following cell to write the images to the log directory.</p></li>
<li><p>Click the <code class="docutils literal notranslate"><span class="pre">refresh</span></code> button on the top of the previous TensorBoard panel.</p></li>
<li><p>Click the <code class="docutils literal notranslate"><span class="pre">IMAGE</span></code> tab to show the images.</p></li>
</ul>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="k">if</span> <span class="nb">input</span><span class="p">(</span><span class="s1">&#39;Execute? [Y/n]&#39;</span><span class="p">)</span><span class="o">.</span><span class="n">lower</span><span class="p">()</span> <span class="o">!=</span> <span class="s1">&#39;n&#39;</span><span class="p">:</span>
    <span class="n">file_writer</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">summary</span><span class="o">.</span><span class="n">create_file_writer</span><span class="p">(</span><span class="n">log_dir</span><span class="p">)</span>

    <span class="k">with</span> <span class="n">file_writer</span><span class="o">.</span><span class="n">as_default</span><span class="p">():</span>
        <span class="c1"># Don&#39;t forget to reshape.</span>
        <span class="n">images</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">reshape</span><span class="p">([</span><span class="n">image</span> <span class="k">for</span> <span class="p">(</span><span class="n">image</span><span class="p">,</span> <span class="n">label</span><span class="p">)</span> <span class="ow">in</span> <span class="n">ds</span><span class="p">[</span><span class="s2">&quot;train&quot;</span><span class="p">]</span><span class="o">.</span><span class="n">take</span><span class="p">(</span><span class="mi">25</span><span class="p">)],</span>
                            <span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="mi">28</span><span class="p">,</span> <span class="mi">28</span><span class="p">,</span> <span class="mi">1</span><span class="p">))</span>
        <span class="n">tf</span><span class="o">.</span><span class="n">summary</span><span class="o">.</span><span class="n">image</span><span class="p">(</span><span class="s2">&quot;25 training data examples&quot;</span><span class="p">,</span>
                         <span class="n">images</span><span class="p">,</span>
                         <span class="n">max_outputs</span><span class="o">=</span><span class="mi">25</span><span class="p">,</span>
                         <span class="n">step</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<p>In addition to presenting the results, TensorBoard is useful for debugging deep learning. In particular, learn</p>
<ul class="simple">
<li><p>to check the model graph under the <a class="reference external" href="https://www.tensorflow.org/tensorboard/graphs"><code class="docutils literal notranslate"><span class="pre">GRAPHS</span></code></a> tab,</p></li>
<li><p>to debug using the <a class="reference external" href="https://www.tensorflow.org/tensorboard/debugger_v2"><code class="docutils literal notranslate"><span class="pre">DEBUGGER</span> <span class="pre">v2</span></code> tab</a>, and</p></li>
<li><p>to <a class="reference external" href="https://www.tensorflow.org/tensorboard/get_started#tensorboarddev_host_and_share_your_ml_experiment_results">publish your results</a>.</p></li>
</ul>
<p>TensorBoard can also show simultaneously the logs of different runs stored in different subfolders of the log directory:</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="k">if</span> <span class="nb">input</span><span class="p">(</span><span class="s1">&#39;Execute? [Y/n]&#39;</span><span class="p">)</span><span class="o">.</span><span class="n">lower</span><span class="p">()</span> <span class="o">!=</span> <span class="s1">&#39;n&#39;</span><span class="p">:</span>
    <span class="o">%</span><span class="k">load_ext</span> tensorboard
    <span class="o">%</span><span class="k">tensorboard</span> --logdir {log_root}
</pre></div>
</div>
</div>
</div>
<p>You can select different runs on the left panel to compare their performance.</p>
<p>Note that loading the log to TensorBoard may consume a lot of memory. You can list the TensorBoard notebook instances and kill those you do not need anymore by running <code class="docutils literal notranslate"><span class="pre">!kill</span> <span class="pre">{pid}</span></code>.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">tensorboard</span> <span class="k">as</span> <span class="nn">tb</span>
<span class="n">tb</span><span class="o">.</span><span class="n">notebook</span><span class="o">.</span><span class="n">list</span><span class="p">()</span> <span class="c1"># list all the running TensorBoard notebooks.</span>

<span class="n">pids_to_kill</span> <span class="o">=</span> <span class="p">[]</span> <span class="c1"># modify the list of pid to kill</span>
<span class="k">for</span> <span class="n">pid</span> <span class="ow">in</span> <span class="n">pids_to_kill</span><span class="p">:</span> 
    <span class="o">!</span><span class="nb">kill</span> <span class="o">{</span>pid<span class="o">}</span>
</pre></div>
</div>
</div>
</div>
<p><strong>Exercise</strong> Train the following network with <a class="reference external" href="https://en.wikipedia.org/wiki/Dilution_(neural_networks)#Dropout">dropout</a>. Try to tune the network for the best accuracy. Use <code class="docutils literal notranslate"><span class="pre">log_root='logs/dropout/'</span></code> to so your log will also be submitted along with your notebook. Put your training code inside the body of the conditional <code class="docutils literal notranslate"><span class="pre">if</span> <span class="pre">input...</span></code> for autograding to work.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="k">def</span> <span class="nf">create_dropout_model</span><span class="p">():</span>
    <span class="n">model</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">keras</span><span class="o">.</span><span class="n">models</span><span class="o">.</span><span class="n">Sequential</span><span class="p">([</span>
        <span class="n">tf</span><span class="o">.</span><span class="n">keras</span><span class="o">.</span><span class="n">layers</span><span class="o">.</span><span class="n">Flatten</span><span class="p">(</span><span class="n">input_shape</span><span class="o">=</span><span class="p">(</span><span class="mi">28</span><span class="p">,</span> <span class="mi">28</span><span class="p">,</span> <span class="mi">1</span><span class="p">)),</span>
        <span class="n">tf</span><span class="o">.</span><span class="n">keras</span><span class="o">.</span><span class="n">layers</span><span class="o">.</span><span class="n">Dense</span><span class="p">(</span><span class="mi">128</span><span class="p">,</span> <span class="n">activation</span><span class="o">=</span><span class="n">tf</span><span class="o">.</span><span class="n">keras</span><span class="o">.</span><span class="n">activations</span><span class="o">.</span><span class="n">relu</span><span class="p">),</span>
        <span class="n">tf</span><span class="o">.</span><span class="n">keras</span><span class="o">.</span><span class="n">layers</span><span class="o">.</span><span class="n">Dropout</span><span class="p">(</span><span class="mf">0.2</span><span class="p">),</span>  <span class="c1"># dropout</span>
        <span class="n">tf</span><span class="o">.</span><span class="n">keras</span><span class="o">.</span><span class="n">layers</span><span class="o">.</span><span class="n">Dense</span><span class="p">(</span><span class="mi">10</span><span class="p">,</span> <span class="n">activation</span><span class="o">=</span><span class="n">tf</span><span class="o">.</span><span class="n">keras</span><span class="o">.</span><span class="n">activations</span><span class="o">.</span><span class="n">softmax</span><span class="p">)</span>
    <span class="p">],</span> <span class="n">name</span><span class="o">=</span><span class="s2">&quot;Dropout&quot;</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">model</span>


<span class="n">model</span> <span class="o">=</span> <span class="n">compile_model</span><span class="p">(</span><span class="n">create_dropout_model</span><span class="p">())</span>
<span class="nb">print</span><span class="p">(</span><span class="n">model</span><span class="o">.</span><span class="n">summary</span><span class="p">())</span>
<span class="n">log_root</span> <span class="o">=</span> <span class="s1">&#39;logs/dropout/&#39;</span>

<span class="k">if</span> <span class="nb">input</span><span class="p">(</span><span class="s1">&#39;Train? [Y/n]&#39;</span><span class="p">)</span><span class="o">.</span><span class="n">lower</span><span class="p">()</span> <span class="o">!=</span> <span class="s1">&#39;n&#39;</span><span class="p">:</span>
    <span class="c1"># YOUR CODE HERE</span>
    <span class="k">raise</span> <span class="ne">NotImplementedError</span><span class="p">()</span>
</pre></div>
</div>
</div>
</div>
<p><strong>Exercise</strong> Explore the <a class="reference external" href="https://en.wikipedia.org/wiki/Convolutional_neural_network">convolutional neural network (CNN)</a>. Try to tune the network for the best accuracy.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="k">def</span> <span class="nf">create_cnn_model</span><span class="p">():</span>
    <span class="n">model</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">keras</span><span class="o">.</span><span class="n">models</span><span class="o">.</span><span class="n">Sequential</span><span class="p">([</span>
        <span class="n">tf</span><span class="o">.</span><span class="n">keras</span><span class="o">.</span><span class="n">layers</span><span class="o">.</span><span class="n">Conv2D</span><span class="p">(</span><span class="mi">32</span><span class="p">,</span>
                               <span class="mi">3</span><span class="p">,</span>
                               <span class="n">activation</span><span class="o">=</span><span class="s1">&#39;relu&#39;</span><span class="p">,</span>
                               <span class="n">input_shape</span><span class="o">=</span><span class="p">(</span><span class="mi">28</span><span class="p">,</span> <span class="mi">28</span><span class="p">,</span> <span class="mi">1</span><span class="p">)),</span>
        <span class="n">tf</span><span class="o">.</span><span class="n">keras</span><span class="o">.</span><span class="n">layers</span><span class="o">.</span><span class="n">MaxPooling2D</span><span class="p">(),</span>
        <span class="n">tf</span><span class="o">.</span><span class="n">keras</span><span class="o">.</span><span class="n">layers</span><span class="o">.</span><span class="n">Flatten</span><span class="p">(),</span>
        <span class="n">tf</span><span class="o">.</span><span class="n">keras</span><span class="o">.</span><span class="n">layers</span><span class="o">.</span><span class="n">Dense</span><span class="p">(</span><span class="mi">64</span><span class="p">,</span> <span class="n">activation</span><span class="o">=</span><span class="s1">&#39;relu&#39;</span><span class="p">),</span>
        <span class="n">tf</span><span class="o">.</span><span class="n">keras</span><span class="o">.</span><span class="n">layers</span><span class="o">.</span><span class="n">Dense</span><span class="p">(</span><span class="mi">10</span><span class="p">,</span> <span class="n">activation</span><span class="o">=</span><span class="s1">&#39;softmax&#39;</span><span class="p">)</span>
    <span class="p">],</span> <span class="n">name</span><span class="o">=</span><span class="s2">&quot;CNN&quot;</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">model</span>


<span class="n">model</span> <span class="o">=</span> <span class="n">compile_model</span><span class="p">(</span><span class="n">create_cnn_model</span><span class="p">())</span>
<span class="nb">print</span><span class="p">(</span><span class="n">model</span><span class="o">.</span><span class="n">summary</span><span class="p">())</span>
<span class="n">log_root</span> <span class="o">=</span> <span class="s1">&#39;logs/cnn/&#39;</span>

<span class="k">if</span> <span class="nb">input</span><span class="p">(</span><span class="s1">&#39;Train? [Y/n]&#39;</span><span class="p">)</span><span class="o">.</span><span class="n">lower</span><span class="p">()</span> <span class="o">!=</span> <span class="s1">&#39;n&#39;</span><span class="p">:</span>
    <span class="c1"># YOUR CODE HERE</span>
    <span class="k">raise</span> <span class="ne">NotImplementedError</span><span class="p">()</span>
</pre></div>
</div>
</div>
</div>
<p><strong>Exercise</strong> Launch TensorBoard to show the best performances of each of the two neural network architectures. Note that to clean up the log of the inferior results, you may need to kill the TensorBoard instance. It is easier to use the vscode interface or the terminal in the lab interface to remove folders.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="k">if</span> <span class="nb">input</span><span class="p">(</span><span class="s1">&#39;Execute? [Y/n]&#39;</span><span class="p">)</span><span class="o">.</span><span class="n">lower</span><span class="p">()</span> <span class="o">!=</span> <span class="s1">&#39;n&#39;</span><span class="p">:</span>
    <span class="c1"># YOUR CODE HERE</span>
    <span class="k">raise</span> <span class="ne">NotImplementedError</span><span class="p">()</span>
</pre></div>
</div>
</div>
</div>
</div>
</div>
<div class="section" id="deployment">
<h2>Deployment<a class="headerlink" href="#deployment" title="Permalink to this headline">Â¶</a></h2>
<p>Once you are satisfied with the result, you can deploy the model as a web application.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">model</span><span class="o">.</span><span class="n">save</span><span class="p">(</span><span class="s1">&#39;model.h5&#39;</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<p>Convert the model to files in <code class="docutils literal notranslate"><span class="pre">mnist/model</span></code> that can be loaded by <a class="reference external" href="https://www.tensorflow.org/js"><code class="docutils literal notranslate"><span class="pre">tensorflow.js</span></code></a> on the page <code class="docutils literal notranslate"><span class="pre">mnist/index.html</span></code>.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="o">!</span>tensorflowjs_converter --input_format keras <span class="s1">&#39;model.h5&#39;</span> <span class="s1">&#39;mnist/model&#39;</span>
</pre></div>
</div>
</div>
</div>
<p>To download the <code class="docutils literal notranslate"><span class="pre">mnist</span></code> folder, we first compress it as follows:</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="o">!</span>zip -r mnist.zip mnist/* index.html
</pre></div>
</div>
</div>
</div>
<p>Finally, you can download the zip file <span class="xref myst">here</span> and host the web application on a static web server.</p>
</div>
</div>

    <script type="text/x-thebe-config">
    {
        requestKernel: true,
        binderOptions: {
            repo: "ccha23/cs5483",
            ref: "main",
        },
        codeMirrorConfig: {
            theme: "abcdef",
            mode: "python"
        },
        kernelOptions: {
            kernelName: "python3",
            path: "./Tutorial7"
        },
        predefinedOutput: true
    }
    </script>
    <script>kernelName = 'python3'</script>

              </div>
              
        </div>
    </div>
    
    
    <div class='prev-next-bottom'>
        
    <a class='left-prev' id="prev-link" href="../Tutorial6/Machine%20vs%20Machine.html" title="previous page">Machine vs Machine</a>
    <a class='right-next' id="next-link" href="../Tutorial8/Partitional%20Clustering.html" title="next page">Partitional Clustering</a>

    </div>
    <footer class="footer mt-5 mt-md-0">
    <div class="container">
      <p>
        
          By Chung Chan<br/>
        
            &copy; Copyright 2020.<br/>
      </p>
    </div>
  </footer>
</main>


      </div>
    </div>

    
  <script src="../_static/js/index.3da636dd464baa7582d2.js"></script>


    
  </body>
</html>